{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63785634",
   "metadata": {},
   "source": [
    "# Power your products with ChatGPT and your own data\n",
    "\n",
    "This is a walkthrough taking readers through how to build starter Q&A and Chatbot applications using the ChatGPT API and their own data. \n",
    "\n",
    "It is laid out in these sections:\n",
    "- **Setup:** \n",
    "    - Initiate variables and source the data\n",
    "- **Lay the foundations:**\n",
    "    - Set up the vector database to accept vectors and data\n",
    "    - Load the dataset, chunk the data up for embedding and store in the vector database\n",
    "- **Make it a product:**\n",
    "    - Add a retrieval step where users provide queries and we return the most relevant entries\n",
    "    - Summarise search results with GPT-3\n",
    "    - Test out this basic Q&A app in Streamlit\n",
    "- **Build your moat:**\n",
    "    - Create an Assistant class to manage context and interact with our bot\n",
    "    - Use the Chatbot to answer questions using semantic search context\n",
    "    - Test out this basic Chatbot app in Streamlit\n",
    "    \n",
    "Upon completion, you have the building blocks to create your own production chatbot or Q&A application using OpenAI APIs and a vector database.\n",
    "\n",
    "This notebook was originally presented with [these slides](https://drive.google.com/file/d/1dB-RQhZC_Q1iAsHkNNdkqtxxXqYODFYy/view?usp=share_link), which provide visual context for this journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59f08ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:25.778700Z",
     "start_time": "2023-05-31T23:28:25.573880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbb963fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.540326Z",
     "start_time": "2023-05-31T23:28:25.631824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.24.2)\r\n",
      "Requirement already satisfied: openai==0.27.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.27.1)\r\n",
      "Requirement already satisfied: pandas==1.5.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.5.3)\r\n",
      "Requirement already satisfied: redis==4.5.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.5.1)\r\n",
      "Requirement already satisfied: requests==2.28.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.28.2)\r\n",
      "Requirement already satisfied: streamlit==1.20.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.20.0)\r\n",
      "Requirement already satisfied: streamlit_chat==0.0.2.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.0.2.2)\r\n",
      "Requirement already satisfied: termcolor==2.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.2.0)\r\n",
      "Requirement already satisfied: jupyter in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.0.0)\r\n",
      "Requirement already satisfied: ipykernel in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (6.22.0)\r\n",
      "Requirement already satisfied: textract in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (1.6.5)\r\n",
      "Requirement already satisfied: tiktoken in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.3.3)\r\n",
      "Requirement already satisfied: pdfminer in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (20191125)\r\n",
      "Requirement already satisfied: tqdm in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from openai==0.27.1->-r requirements.txt (line 2)) (4.65.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from openai==0.27.1->-r requirements.txt (line 2)) (3.8.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 3)) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 3)) (2023.3)\r\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from redis==4.5.1->-r requirements.txt (line 4)) (4.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from requests==2.28.2->-r requirements.txt (line 5)) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from requests==2.28.2->-r requirements.txt (line 5)) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from requests==2.28.2->-r requirements.txt (line 5)) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from requests==2.28.2->-r requirements.txt (line 5)) (2022.12.7)\r\n",
      "Requirement already satisfied: altair<5,>=3.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (4.2.2)\r\n",
      "Requirement already satisfied: blinker>=1.0.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (1.6.2)\r\n",
      "Requirement already satisfied: cachetools>=4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (5.3.0)\r\n",
      "Requirement already satisfied: click>=7.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (8.1.3)\r\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (6.6.0)\r\n",
      "Requirement already satisfied: packaging>=14.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (23.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (9.5.0)\r\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (3.20.3)\r\n",
      "Requirement already satisfied: pyarrow>=4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (11.0.0)\r\n",
      "Requirement already satisfied: pympler>=0.9 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (1.0.1)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (13.3.5)\r\n",
      "Requirement already satisfied: semver in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (3.0.0)\r\n",
      "Requirement already satisfied: toml in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (0.10.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (4.5.0)\r\n",
      "Requirement already satisfied: tzlocal>=1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (4.3)\r\n",
      "Requirement already satisfied: validators>=0.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (0.20.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (3.1.31)\r\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (0.8.1b0)\r\n",
      "Requirement already satisfied: tornado>=6.0.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (6.3.1)\r\n",
      "Requirement already satisfied: notebook in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (6.5.4)\r\n",
      "Requirement already satisfied: qtconsole in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (5.4.2)\r\n",
      "Requirement already satisfied: jupyter-console in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (6.6.3)\r\n",
      "Requirement already satisfied: nbconvert in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (7.3.1)\r\n",
      "Requirement already satisfied: ipywidgets in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (8.0.6)\r\n",
      "Requirement already satisfied: appnope in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (0.1.3)\r\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (0.1.3)\r\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (1.6.7)\r\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (8.12.0)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (8.2.0)\r\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (5.3.0)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (0.1.6)\r\n",
      "Requirement already satisfied: nest-asyncio in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (1.5.6)\r\n",
      "Requirement already satisfied: psutil in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (5.9.5)\r\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (25.0.2)\r\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (5.9.0)\r\n",
      "Requirement already satisfied: argcomplete~=1.10.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (1.10.3)\r\n",
      "Requirement already satisfied: beautifulsoup4~=4.8.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (4.8.2)\r\n",
      "Requirement already satisfied: chardet==3.* in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (3.0.4)\r\n",
      "Requirement already satisfied: docx2txt~=0.8 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (0.8)\r\n",
      "Requirement already satisfied: extract-msg<=0.29.* in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (0.28.7)\r\n",
      "Requirement already satisfied: pdfminer.six==20191110 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (20191110)\r\n",
      "Requirement already satisfied: python-pptx~=0.6.18 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (0.6.21)\r\n",
      "Requirement already satisfied: six~=1.12.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (1.12.0)\r\n",
      "Requirement already satisfied: SpeechRecognition~=3.8.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (3.8.1)\r\n",
      "Requirement already satisfied: xlrd~=1.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (1.2.0)\r\n",
      "Requirement already satisfied: pycryptodome in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pdfminer.six==20191110->textract->-r requirements.txt (line 11)) (3.17)\r\n",
      "Requirement already satisfied: sortedcontainers in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pdfminer.six==20191110->textract->-r requirements.txt (line 11)) (2.4.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 12)) (2023.3.23)\r\n",
      "Requirement already satisfied: entrypoints in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (0.4)\r\n",
      "Requirement already satisfied: jinja2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (3.1.2)\r\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (4.17.3)\r\n",
      "Requirement already satisfied: toolz in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (0.12.0)\r\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from beautifulsoup4~=4.8.0->textract->-r requirements.txt (line 11)) (2.4.1)\r\n",
      "Requirement already satisfied: imapclient==2.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract->-r requirements.txt (line 11)) (2.1.0)\r\n",
      "Requirement already satisfied: olefile>=0.46 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract->-r requirements.txt (line 11)) (0.46)\r\n",
      "Requirement already satisfied: compressed-rtf>=1.0.6 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract->-r requirements.txt (line 11)) (1.0.6)\r\n",
      "Requirement already satisfied: ebcdic>=1.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract->-r requirements.txt (line 11)) (1.1.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from gitpython!=3.1.19->streamlit==1.20.0->-r requirements.txt (line 6)) (4.0.10)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from importlib-metadata>=1.4->streamlit==1.20.0->-r requirements.txt (line 6)) (3.15.0)\r\n",
      "Requirement already satisfied: backcall in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.2.0)\r\n",
      "Requirement already satisfied: decorator in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.18.2)\r\n",
      "Requirement already satisfied: pickleshare in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (3.0.38)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (2.15.1)\r\n",
      "Requirement already satisfied: stack-data in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.6.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (4.8.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 10)) (3.5.0)\r\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract->-r requirements.txt (line 11)) (4.9.2)\r\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract->-r requirements.txt (line 11)) (3.1.0)\r\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from rich>=10.11.0->streamlit==1.20.0->-r requirements.txt (line 6)) (2.2.0)\r\n",
      "Requirement already satisfied: pytz-deprecation-shim in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from tzlocal>=1.1->streamlit==1.20.0->-r requirements.txt (line 6)) (0.1.0.post0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (1.3.1)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 9)) (4.0.7)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 9)) (3.0.7)\r\n",
      "Requirement already satisfied: bleach in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (6.0.0)\r\n",
      "Requirement already satisfied: defusedxml in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (0.7.1)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (0.2.2)\r\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (2.1.2)\r\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (2.0.5)\r\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (0.7.4)\r\n",
      "Requirement already satisfied: nbformat>=5.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (5.8.0)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (1.5.0)\r\n",
      "Requirement already satisfied: tinycss2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (1.2.1)\r\n",
      "Requirement already satisfied: argon2-cffi in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (21.3.0)\r\n",
      "Requirement already satisfied: ipython-genutils in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (0.2.0)\r\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (1.8.2)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (0.17.1)\r\n",
      "Requirement already satisfied: prometheus-client in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (0.16.0)\r\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (0.5.6)\r\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from qtconsole->jupyter->-r requirements.txt (line 9)) (2.3.1)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.20.0->-r requirements.txt (line 6)) (5.0.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.8.3)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (0.19.3)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit==1.20.0->-r requirements.txt (line 6)) (0.1.2)\r\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (2.5.0)\r\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.2.3)\r\n",
      "Requirement already satisfied: fastjsonschema in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 9)) (2.16.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.2.6)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 9)) (21.2.0)\r\n",
      "Requirement already satisfied: webencodings in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 9)) (0.5.1)\r\n",
      "Requirement already satisfied: tzdata in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit==1.20.0->-r requirements.txt (line 6)) (2023.3)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.2.2)\r\n",
      "Requirement already satisfied: anyio>=3.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (3.6.2)\r\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.6.3)\r\n",
      "Requirement already satisfied: jupyter-server-terminals in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.4.4)\r\n",
      "Requirement already satisfied: websocket-client in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (1.5.1)\r\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 9)) (1.15.1)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (1.3.0)\r\n",
      "Requirement already satisfied: pycparser in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 9)) (2.21)\r\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (2.0.7)\r\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (6.0)\r\n",
      "Requirement already satisfied: rfc3339-validator in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.1.4)\r\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.1.1)\r\n",
      "Requirement already satisfied: fqdn in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (1.5.1)\r\n",
      "Requirement already satisfied: isoduration in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (20.11.0)\r\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (2.3)\r\n",
      "Requirement already satisfied: uri-template in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (1.2.0)\r\n",
      "Requirement already satisfied: webcolors>=1.11 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (1.13)\r\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from isoduration->jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (1.2.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13649895",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we'll setup our libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7590fbfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:42:31.216449Z",
     "start_time": "2023-06-01T00:42:30.675797Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Iterator\n",
    "import tiktoken\n",
    "import textract\n",
    "from numpy import array, average\n",
    "\n",
    "from database import get_redis_connection\n",
    "\n",
    "# Set our default models and chunking size\n",
    "from config import COMPLETIONS_MODEL, EMBEDDINGS_MODEL, CHAT_MODEL, TEXT_EMBEDDING_CHUNK_SIZE, VECTOR_FIELD_NAME\n",
    "\n",
    "# Ignore unclosed SSL socket warnings - optional in case you get these errors\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ImportWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760efc1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:42:34.474628Z",
     "start_time": "2023-06-01T00:42:34.469607Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f90817d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:51:36.151384Z",
     "start_time": "2023-06-01T00:51:36.128777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['37c3ac58-92da-41ec-89ee-1bb382e82a64_Pairing_Interview.pdf',\n '6ae2971a-a017-401e-aa9d-c72e4a9b2fa9_Pairing.pdf',\n '77c3f98c-bf1b-45b5-b4a5-8276c5508587_Tech_Lead.pdf',\n '8a424ee2-b1d7-41c3-a1f2-43160b949896_Why_we_do_what_we_do.pdf',\n '94550ad9-5435-4814-9222-fa69e1074ee6_Pair_Retros.pdf',\n 'a0922c1c-012c-445a-bd0c-17c5e380af70_Project_Rotations.pdf',\n 'ac00bd07-b307-4a97-becc-0e79913831ba_2023_Strategy.pdf',\n 'bafc416e-9abb-4496-ac43-343895b2021e_The_Denver_Office.pdf',\n 'c6c651e3-2d90-480e-aa54-9915022f5e7a_Pairing.pdf',\n 'c94b9664-d316-4bbf-bfaa-d6f11c0ad7ab_Product__Design_Lunch.pdf',\n 'de95e697-2d3c-4bf7-af90-8cca954d7410_Software_Development.pdf',\n 'e4fd509a-4447-4a60-bafa-ac85cfd40797_So_you_want_to_be_a_TPIer.pdf',\n 'e67cd5c9-c8ea-4ce2-a028-8b8c2fcc3e77_Anchors.pdf',\n 'ff157be3-a2d2-4bfc-bffa-6627abb59a79_2023_Strategy.pdf']"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(os.curdir,'data')\n",
    "pdf_files = sorted([x for x in os.listdir(data_dir) if 'DS_Store' not in x])\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4018c",
   "metadata": {},
   "source": [
    "## Laying the foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b82ed",
   "metadata": {},
   "source": [
    "### Storage\n",
    "\n",
    "We're going to use Redis as our database for both document contents and the vector embeddings. You will need the full Redis Stack to enable use of Redisearch, which is the module that allows semantic search - more detail is in the [docs for Redis Stack](https://redis.io/docs/stack/get-started/install/docker/).\n",
    "\n",
    "To set this up locally, you will need to install Docker and then run the following command: ```docker run -d --name redis-stack -p 6379:6379 -p 8001:8001 redis/redis-stack:latest```.\n",
    "\n",
    "The code used here draws heavily on [this repo](https://github.com/RedisAI/vecsim-demo).\n",
    "\n",
    "After setting up the Docker instance of Redis Stack, you can follow the below instructions to initiate a Redis connection and create a Hierarchical Navigable Small World (HNSW) index for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d6b886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:42:42.077645Z",
     "start_time": "2023-06-01T00:42:42.062682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup Redis\n",
    "from redis import Redis\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.field import (\n",
    "    TextField,\n",
    "    VectorField,\n",
    "    NumericField\n",
    ")\n",
    "from redis.commands.search.indexDefinition import (\n",
    "    IndexDefinition,\n",
    "    IndexType\n",
    ")\n",
    "\n",
    "redis_client = get_redis_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f3d3e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:42:44.589507Z",
     "start_time": "2023-06-01T00:42:44.582294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "VECTOR_DIM = 1536 #len(data['title_vector'][0]) # length of the vectors\n",
    "#VECTOR_NUMBER = len(data)                 # initial number of vectors\n",
    "PREFIX = \"focusedlabsdoc\"                            # prefix for the document keys\n",
    "DISTANCE_METRIC = \"COSINE\"                # distance metric for the vectors (ex. COSINE, IP, L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c352ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:42:45.462192Z",
     "start_time": "2023-06-01T00:42:45.452539Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create search index\n",
    "\n",
    "# Index\n",
    "INDEX_NAME = \"fl-index\"           # name of the search index\n",
    "VECTOR_FIELD_NAME = 'content_vector'\n",
    "\n",
    "# Define RediSearch fields for each of the columns in the dataset\n",
    "# This is where you should add any additional metadata you want to capture\n",
    "filename = TextField(\"filename\")\n",
    "text_chunk = TextField(\"text_chunk\")\n",
    "file_chunk_index = NumericField(\"file_chunk_index\")\n",
    "\n",
    "# define RediSearch vector fields to use HNSW index\n",
    "\n",
    "text_embedding = VectorField(VECTOR_FIELD_NAME,\n",
    "    \"HNSW\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": VECTOR_DIM,\n",
    "        \"DISTANCE_METRIC\": DISTANCE_METRIC\n",
    "    }\n",
    ")\n",
    "# Add all our field objects to a list to be created as an index\n",
    "fields = [filename,text_chunk,file_chunk_index,text_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6c78b7e",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-06-01T00:42:47.711358Z",
     "start_time": "2023-06-01T00:42:47.699313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf3ad41f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:42:49.272061Z",
     "start_time": "2023-06-01T00:42:49.253687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index already exists\n"
     ]
    }
   ],
   "source": [
    "# Optional step to drop the index if it already exists\n",
    "#redis_client.ft(INDEX_NAME).dropindex()\n",
    "\n",
    "# Check if index exists\n",
    "try:\n",
    "    redis_client.ft(INDEX_NAME).info()\n",
    "    print(\"Index already exists\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    # Create RediSearch Index\n",
    "    print('Not there yet. Creating')\n",
    "    redis_client.ft(INDEX_NAME).create_index(\n",
    "        fields = fields,\n",
    "        definition = IndexDefinition(prefix=[PREFIX], index_type=IndexType.HASH)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ebeb5",
   "metadata": {},
   "source": [
    "### Ingestion\n",
    "\n",
    "We'll load up our PDFs and do the following\n",
    "- Initiate our tokenizer\n",
    "- Run a processing pipeline to:\n",
    "    - Mine the text from each PDF\n",
    "    - Split them into chunks and embed them\n",
    "    - Store them in Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed23bf9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:42:57.205421Z",
     "start_time": "2023-06-01T00:42:57.190130Z"
    }
   },
   "outputs": [],
   "source": [
    "# The transformers.py file contains all of the transforming functions, including ones to chunk, embed and load data\n",
    "# For more details the file and work through each function individually\n",
    "from transformers import handle_file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3912ecdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:42:59.421902Z",
     "start_time": "2023-06-01T00:42:58.352487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textract in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (1.6.5)\r\n",
      "Requirement already satisfied: argcomplete~=1.10.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (1.10.3)\r\n",
      "Requirement already satisfied: beautifulsoup4~=4.8.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (4.8.2)\r\n",
      "Requirement already satisfied: chardet==3.* in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (3.0.4)\r\n",
      "Requirement already satisfied: docx2txt~=0.8 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (0.8)\r\n",
      "Requirement already satisfied: extract-msg<=0.29.* in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (0.28.7)\r\n",
      "Requirement already satisfied: pdfminer.six==20191110 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (20191110)\r\n",
      "Requirement already satisfied: python-pptx~=0.6.18 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (0.6.21)\r\n",
      "Requirement already satisfied: six~=1.12.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (1.12.0)\r\n",
      "Requirement already satisfied: SpeechRecognition~=3.8.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (3.8.1)\r\n",
      "Requirement already satisfied: xlrd~=1.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (1.2.0)\r\n",
      "Requirement already satisfied: pycryptodome in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (3.17)\r\n",
      "Requirement already satisfied: sortedcontainers in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (2.4.0)\r\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from beautifulsoup4~=4.8.0->textract) (2.4.1)\r\n",
      "Requirement already satisfied: imapclient==2.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (2.1.0)\r\n",
      "Requirement already satisfied: olefile>=0.46 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (0.46)\r\n",
      "Requirement already satisfied: tzlocal>=2.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (4.3)\r\n",
      "Requirement already satisfied: compressed-rtf>=1.0.6 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (1.0.6)\r\n",
      "Requirement already satisfied: ebcdic>=1.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (1.1.1)\r\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (4.9.2)\r\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (9.5.0)\r\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (3.1.0)\r\n",
      "Requirement already satisfied: pytz-deprecation-shim in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (0.1.0.post0)\r\n",
      "Requirement already satisfied: tzdata in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal>=2.1->extract-msg<=0.29.*->textract) (2023.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install textract --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f299f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:53:38.546028Z",
     "start_time": "2023-06-01T00:51:57.514364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/37c3ac58-92da-41ec-89ee-1bb382e82a64_Pairing_Interview.pdf\n",
      "processing file: 37c3ac58-92da-41ec-89ee-1bb382e82a64_Pairing_Interview.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file 37c3ac58-92da-41ec-89ee-1bb382e82a64_Pairing_Interview.pdf with contents: Pairing Interview    Focus on Empathy, Aptitude, and Communication    Our Pairing interview is the first gate to working with Focused Labs. Right now we use   an almost exact replica of an interview from a previous company. It's important that we   understand why we replicated this interview and what the goal is.    We use this exercise as our first interview because it is objective, repeatable, canned,   and has a consistent scoring system. The exercise tests a candidate's ability to   implement an object oriented solution, test drive that solution, communicate about the   code in that solution, and be empathetic to the boundaries we set. This interview is a   great way to get a quick leading indicator of success and is a lot of fun!    This interview is a leading   indicator of success    This interview is not a 1 to 1   evaluation of the candidates   skill    Pairing Interview1Interviewer OverviewScoringScoring RubricLosing PointsEarning PointsEnvironmentBefore an interviewRulesScriptOpeningisEmptysizeRefactor - Remove empty stateRefactor - Dry up tests🦄  💡  🚨  \fInterviewer Overview  The interview takes somewhere between 30 minutes - 1 hour to complete. The time it   takes to finish is not an indicator of the competency or quality of the candidate.     During the hour the interviewer will guide the candidate through developing a Set class   in Java through test driven development.    It's the interviewers job to finish the entire exercise in the allotted time no-matter the   candidates performance.    The job of the interviewer is to make the time a productive, friendly, and kind experience   with the candidate. Make sure you evaluate fairly.    You should avoid using your mouse at all costs and know the key bindings like the back   of your hand.    Remember every interview should end exactly the same.    Scoring  Scoring Rubric  This interview is scored from 100 - 0 (although it's rare to keep a score lower than 85).    When the interview starts the candidate is given 100 points. During the interview as we   ask questions of the candidate the interviewer will either add or remove points from a   candidate. It is possible, although very rare, for a candidate to score over 100.    Losing Points  A candidate can lose points for the following:    Pairing Interview2containsremoveRefactor - extract indexOfignoresDuplicatesgrowsEnding the InterviewOther Notes\fIt's at the discretion of the interviewer when to remove a point and how many   to remove. Your judgment is based on if they are discussing a solution with   you, or need you to give them an answer. That said, there are consistent   places throughout the exercise where points are deducted.    Getting a question wrong    Taking too long to answer    Sitting silent and not communicating    Insistent that an approach is correct after the guidance of the interviewer    Generally not being nice or reflecting our values    Earning Points  We often ask similar questions more than once or coach a candidate to a solution. As a   test for aptitude the interviewer should give points back to a candidate if they previously   missed something that they then got correct.    Candidates can also earn points by spotting bugs, being exceptionally clever or smart,   or having elevated conversations about the why of how the code is being written or   structured    Environment    IntelliJ should be set up with two panes side by side. On the left the implementation.   On the right the test class.    Colors should be accessible and color blind friendly    Font sizes should be greater than 15    Before an interview    Open the interview template and with a completed test and implementation class   run your test to make sure packages are updated and code can run    Clear out the entire contents of the implementation class leaving only the skeleton   of the Set    Pairing Interview3💡  \fpackage interview       public class Set {   }    Clear out the contests of the test class leaving only the imports and skeleton.    package interview       import org.junit.Before    import org.junit.Test       import static org.junit.Assert.*       public class SetTest {   }    Run your tests to ensure that the empty classes run    Rules    The exercise will be done in Java.  The implementation is restricted to Java primitives and no imports (this means no   collections classes)    The candidate is not allowed to type    We have found asking candidates to type when they aren't experienced in   the stack or are not comfortable typing in front of others creates a   negative experience that can cause a high quality candidate to preform   poorly. By typing ourselves we focus on empathy, aptitude, and   communication. It also forces the candidate to articulate precisely about   the code they wish to drive out, which is a fundamental skill of any good   pair.    Pairing Interview4❔  \fThe candidate is not expected to know Java but instead expected to articulate intent   clearly and accurately about the code they are proposing    Script    ‼ It is important that anything in a quote block should be said exactly as is written.   This guarantees a fair playing field and consistent results between candidates.    Opening  The opening is not scored.    Open by explaining the above rules to the candidate. After they have a clear   understanding of the rules ask them     Do you know the characteristics of a set?    The answer is a good indicator of the candidates experience and can help the   interviewer understand if the candidate has a basic understanding of data structures.    No matter the answer of the candidate reiterate that a set is    An unordered collection of unique elements    You should make sure you say this three times    Always run the tests to show them fail then pass. Never refactor while tests   are failing.    isEmpty  Start by implementing a failing test that asserts that all sets are empty and ask the   candidate    What's the simplest thing I can do to make this test pass?    Pairing Interview5💡  \fAfter getting past that test introduce the main three Sets empty  one and many    Add the string \"1\" to one and the strings \"1\" and \"2\" to many.    Implement a three assertions, asserting empty is empty while one and many are not   empty.     You will need to add an add method to the implementation. This method is never   explicitly tested.    Now, what's the simplest thing I can do to make this test pass?    This should be implemented using a boolean field called empty    size  Copy and paste the test from isEmpty and remove the assertions while keeping the prep   part of the test.    The copy and paste is important as it's a soft indicator that there is duplication   that should be refactored later.    Implement a test for size asserting the size of empty is 0 and the size of one is 1.    How do you think we should assert the size of many ?    The candidate should say assert greater than one, any other answer loses points. Feel   free to ask why.    You can hint if you want    Is the there a better way to assert the size of many    This should be implemented using a counter called size .     Pairing Interview6📢  💡  📢  \fDo not refactor empty away until tests are green, and do not allow for the introduction of   an array... yet. Any persistence to do either loses points.    Refactor - Remove empty state    Do you see any refactorings    After green tests remove the empty field and refactor isEmpty to use a boolean return   like so    return size == 0    Refactor - Dry up tests  Refactor your tests to contain a before block.    If the candidate suggests both refactors give them some extra credit.    contains  Write a test that asserts the full truth table of empty  one and many . Empty should not   contain the strings \"1\" and \"2\" , one should contain \"1\" but not \"2\" . many should   contain both \"1\" and \"2\"    The candidate should suggest that we need to store state now. That's correct.     Implement the state as an Object[] named elements with a length of 10.    The candidate now needs to add the elements to the elements array and check that the   array contains the elements. Either can be done first.  Finding the Elements    This should be implemented using a for loop.     If the candidate suggests any loop other than a for loop ask why then drive them to a   for loop.    Pairing Interview7📢  \fUse a generator to generate a for loop. The default generator in IntelliJ is fori as you   are implementing the for loop as the candidate    How far should we loop?    The candidate should suggest size any other answer is a loss of points.    As you iterate though the elements array check that the element at i equals the given   value.  Adding the elements    The candidate should suggest inserting the element at an index, there is no push in   Java. The correct index is size then increment size .    remove  The remove test should be implemented with a new Set . Add two strings \"1\" and \"2\"   to the new Set and then remove \"1\" .    How would you test remove?    This is the first time we ask the candidate to write a test    The candidate should assert the size is 1 and we no longer contain the \"1\"    After getting a successful red test ask the candidate to make the test pass. They should   suggest looping again. Copy paste the contains code, this indicates there is duplication   to clean up. Now delete the contents of the if    This is the hardest part of the interview    Pairing Interview8💡  💡  \fThe correct answer is to move the last element into the spot of the found and then   decrement the size by 1. No other solution is correct or more efficient. I generally do not   remove points if a candidate suggests shifting the contents down, but will remove points   if they require any more prompting than suggesting there's actually a cleaner solution.    We do introduce a memory leak if the candidate does not null out the last element of the   array before decrementing size. Spotting the memory leak is a point.    The if body should look like this    elements[indexOf(value)] = elements[size - 1]    elements[--size] = null     Refactor - extract indexOf  Ask the candidate    Do you see any refactorings    You can extract an indexOf method from both contains and remove .     Index of should use the existing for loop and return -1 if no element is found.    Contains should become one line and the candidate had the potential to introduce a bug   in remove.    If the candidate does not add a guard clause checking the given value is   contained in the array. There is potential for an IndexOutOfBounds exception.   Ask the candidate to spot it and add a test to prevent it    If the candidate adds a guard clause to check the element is contained suggest they   have added untested code and see if they can spot it. If they spot it quickly add points if   it requires coaching remove points.    If the candidate suggests wrapping the the whole method in an if rather than using a   guard clause coach them to a guard    If the candidate suggests using -1 rather than contains ask them why, if they can't   explain the trade of multiple loops vs readability deduct points.    Pairing Interview9🐞  \fThe final method should use a guard that tests if the given value is not contained to   return.    ignoresDuplicates  Add a test that adds \"1\" to one then assert the size of one is 1.    The candidate should suggest a guard clause using the contains method. Anything   other than that loses points.    grows    Make sure you can use IntellJ Generators for this one.    Introduce a single argument constructor and test a new set that has an initial capacity of   1.    Add 2 things to the set and see an OutOfBound exception.    add a check in add if full then grow .    full    How do we know if we are full    Full should check that size == elements.length  grow    How should we grow the Set    Create a new bigger set that is 2x the original size.    Use System.arraycopy to move everything over into the new bigger set and reassign.    Ending the Interview  If the candidate did well and you feel confident in moving them forward to the next   interview, give them this feedback in real time and ask the candidate directly when     Pairing Interview10💡  \fthey are available to come in for a full final day interview.     Ideally, the candidate is able to give you a few days of when they are available. Check   the Focused Labs Interview calendar (below) to see whether the team is available to   interview. If there are no other candidates interviewing, you can tentatively confirm the   candidate for that day. If the candidate provides multiple days, the team's preference   would be to not conduct interviews on Fridays (due to retros and demos). Please put the   candidate's availability in your Greenhouse scorecard as soon as possible so that the   recruiting team can work on coordinating the next interview.     Google Calendar  With Google's free online calendar, it's easy to keep track of life's   important events all in one place.    https://calendar.google.com/calendar/u/0?cid=Y19qbDNsY3Fw  NGllbWI0cTBjdDBoaWo4OWEwMEBncm91cC5jYWxlbmRhci5nb2  9nbGUuY29t    If the candidate did not do well, you can thank them for their time and complete your   Greenhouse scorecard with your feedback.     Other Notes    🪐 TPI Scoring Rubric    Pairing Interview11\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/6ae2971a-a017-401e-aa9d-c72e4a9b2fa9_Pairing.pdf\n",
      "processing file: 6ae2971a-a017-401e-aa9d-c72e4a9b2fa9_Pairing.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file 6ae2971a-a017-401e-aa9d-c72e4a9b2fa9_Pairing.pdf with contents: Pairing    Core Collaboration Practice    Pairing as a practice has existed in the industry for a while and means many things to   many people. This article is super in-depth, https://martinfowler.com/articles/on-pair-  programming.html.     This notion page covers what pairing means to Focused Labs and why it is one of our   core practices.    Pairing1What is pairing to us?It's our defaultWhat is it NOT?Code ReviewsOccasionally for hard problemsWhy default to pairing?How to be a good pair?All around good advice:If you're the confident type...If you're the introverted or struggles-with-impostor-syndrome type...Tools!Additional resources on pairing\u0000  \fWhat is pairing to us?  It's our default    It's not just for blockers anymore!     Pairing here consists of two equal partners writing code together: one computer, but two   of everything else (monitors, keyboards & people). After stand, each team determines   their pairs for the day. We try to rotate our pairs daily unless something that requires a   lot of context is in-flight. Throughout the day, we strive to help each other grow our skills  and share knowledge about the codebase and tools we're using.    While pairing is our default, it's a flexible practice. Sometimes, you wind up with an odd-  numbered team, so you solo for a day. Sometimes, you might be on a one-pair team,   and rotation isn't an issue. We might adjust the practice to current conditions ⛈, but it's   a baseline practice here and something you should expect to spend a fair amount of   time doing.     Pairing isn't only, a practice, it's also a skill. Being a good pair involves being able to   participate in constant feedback and collaboration, for more tips on being a good pair,   keep on reading!    What is it NOT?  Code Reviews  Code review is a hard practice for little return. We have found pairing to be far more   effective, especially for long term sustainability.    Occasionally for hard problems    Pairing is a skill and like any skill, you can only get better at it by doing it.    Pairing2\fIf you are working long term on a significant amount of code that is rote, your   codebase is probably missing an abstraction. A pair will help you find the   appropriate abstractions to avoid this in the future.    Why default to pairing?    The Martin Fowler article linked to above offers a whole host of reasons that   pairing can be beneficial. Here are a few reasons that we like to pair:    💗 Pairing can improve quality of life as a dev. Sometimes writing code solo can be   fun and feel productive, but sometimes... it can go sideways. We've been there: rabbit-  holed for hours on something that was essentially a typo \u0000. The recipient of a PR   review filled with comments on using const vs let ...while leaving the architecture   change you'd like feedback on unmentioned. Receiving feedback on a feature that   you'd spent hours on, and feeling personally attacked or like an impostor 🥊. Pairing is   great for preventing too-deep-in-the-weeds problems, because you've got someone   there to pull you out, and a second set of eyes to see what you can't. You can get   meaningful feedback on what you're writing from someone who has shared context and   shared concerns. Finally, because responsibility for the code is distributed across the   team, we can still have pride in crafting something well, without that feeling of ownership   becoming possessive or defensive. Pairing distributes the burden and shares the joys.    \u0000 Pairing is great for building teams. By working side-by-side with someone,   you're encouraged to reconcile their way of thinking with your own. Getting out of your   own head like this can strengthen everyone's understanding of the task at hand, and   fosters in-depth communication. By switching pairs frequently, no one person holds all   the context, and knowledge is distributed across the team. In the event that you're   onboarding to a new project, or have less experience in a given language or platform,   pairing offers valuable learning opportunities beyond what the docs can provide. And   as the more experienced pair, it offers a chance to learn how to communicate your   knowledge plainly (which is a valuable skill for consultants)  also, nothing cements what   you think you know, like explaining it to someone else 😈.     Pairing3☝  \f✨ Pairing makes for better code. The act of talking through any given feature,   optimizes the code in a few ways. Communicating often requires clarifying your own   thought process and getting immediate feedback on assumptions and understanding.   In making sure that the code that we're pairing on is clear to each other, the code   becomes more readable for others and our future selves. Given a diverse team, people   come from different backgrounds (whether education, workplace, language preference   or just personality), and that diversity gets passed along to the code's style and   approach. Plus, two sets of eyes means fewer bugs 🐛    🦚 Pairing is just good practice.  There are a few     Fosters empathy    You involve people in the design rather than the output    Fast feedback loops    less possessiveness makes introducing client devs to the codebase easier    How to be a good pair?    We only get the benefits of pairing when we're being the best pair we can be.    All around good advice:    Listen first    Take breaks: frequent breaks are key to regaining focus, feeling better and being   able to think on something in your own way    If you're the confident type...    Let your pair to have equal time on the keyboard, and encourage them to drive if   they're hesitant to take the keyboard    Pairing4👐  \fIf you're the person with more context/experience, bring your pair up to speed and   don't just forge ahead without them    If you're the introverted or struggles-with-impostor-syndrome   type...    Speak up: If you're feeling lost or out of context, don't be afraid to raise it. Calling   out confusing code helps to make sure that it's written more clearly.     [ADD MORE]    Tools!  Tuple    Screen    Additional resources on pairing    Austin's Built In Chicago interview    Some work station ideas:   https://www.nomachetejuggling.com/2011/08/25/mechanics-of-good-pairing/    http://llewellynfalco.blogspot.com/2014/06/llewellyns-strong-style-pairing.html?m=1    There's a conference about how to make pairing more inclusive:   https://pearconf.splashthat.com/    Pairing5\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/77c3f98c-bf1b-45b5-b4a5-8276c5508587_Tech_Lead.pdf\n",
      "processing file: 77c3f98c-bf1b-45b5-b4a5-8276c5508587_Tech_Lead.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file 77c3f98c-bf1b-45b5-b4a5-8276c5508587_Tech_Lead.pdf with contents: Tech Lead  What is a Tech Lead at Focused Labs?  The Tech Lead is the technical leader for the Focused Labs developers on a project   team. They are a contributing developer to the team with additional responsibilities and   authority that is accountable for the technical success of the engagement. The role is a   combination of technical, consulting, and leadership skills.    Tech leads are accountable for:    The technical quality of the software delivered    Ensuring that the team is following Focused Labs core development practices    Consulting the client organization on the best technical approach    Maintaining the technical context of the project and being able to explain the ‘why’s’   behind architectural decisions.     The individual in this role is not solely responsible for accomplishing all of the tasks   listed above. Instead, their main responsibility is to guide the team's technical decisions   and ensure that ownership is delegated effectively while maintaining accountability for   Focus Labs's high standards of execution.    The allocations team determines who the Tech Lead is for a project. This is a   project-specific title that a developer holds only for the duration of that project.    Technical  The tech lead should not make decisions alone or hoard all technical project context.   Instead, they should work to align the team's technical direction and incorporate   feedback from other developers in order to make the strongest technical decisions   possible. The tech lead does not need to be an expert in the tech stack or domain when     Tech Lead1🦺  💡  \fthey start a project, but are expected to learn quickly and leverage their team and   existing knowledge to make informed decisions.    The tech lead should lead by example and is expected write code and actively   participate in development. They should spend at least 80% of their time pairing with the   rest of the team. This is critical for preventing knowledge silos, guiding decisions in the   codebase, and maintaining a high level of quality.    Consulting  The tech lead is not only a technical leader but also a trusted technical partner whom   the client seeks out for advice, perspective, and concrete solutions. They should expand   their sphere of influence beyond the core team and build relationships with other client   teams. This is critical for understanding the client's technical landscape, so that the tech   lead can make the best technical decisions based on the client's current position.    Leadership  Leadership on a team is shared with other roles. The product manager and designer   collaborate on what to build while the tech lead is accountable for how to build. The tech   lead guides the team's technical direction, delegates responsibilities effectively, and is   accountable for Focused Labs's high standards of execution. They generate consensus   when then can, and make decisions when necessary.    Responsibilities of the Tech Lead    Ensuring that the team is following core Focused Labs dev practices, including   always delivering working software, TDD, CI/CD, pairing and pair rotations,   managing technical debt, preventing knowledge silos, etc.    Ensuring that the product is production-ready by making sure that cross functional   requirements are met, including performance, security, scalability, monitoring,   logging, documentation, etc.    Understanding the technical requirements of the product and client, and working   closely with PM and design to ensure they are prioritized in the backlog supports   continuously shipping working software    Ensuring architecture decisions fit product and client needs    Tech Lead2\fConsulting the client on technical best practices and advocating for XP core   practices    Growing their sphere of influence outside of the core team by establishing and   maintaining relationships with client technical teams and enterprise architects,   including teams working in the same product area, DevOps, security, etc.    Communicating technical risks, wins, and allocation needs to the Delivery Lead    Most Effective Tech Leads…    Delegate responsibilities rather than doing everything themselves. Although   the Tech Lead is accountable for the success of team initiatives, it is unlikely that   they will be able to effectively do everything by themselves. Tech Leads should seek   to empower their team by removing obstacles, transferring ownership, and avoiding   micromanagement. They use authority tactfully and hold team members   accountable.  Collaborate closely with their cross-functional peers and client leadership.   Success is rarely tied solely to technical outcomes. Effective Tech Leads work with   product, design, architecture, and other teams to make informed decisions. They   are a technical partner and make informed decisions in the context of a client’s   technical landscape.    Contribute to a healthy team environment by setting an example. Good leaders   seek feedback often to make course corrections. They have a good sense of team   morale and promote open communication among team members to proactively   prevent interpersonal conflict. They address team issues directly and escalate when   necessary.    Act as a primary point of contact but not the only point of contact. An effective   Tech Lead manages their time well. They build client relationships while balancing   their time as a technical contributor. This means being selective about the meetings   that they need to attend and looking for opportunities to volunteer team members in   their place.    Logistics  Role Requirements    Tech Lead3\fSenior+ software developer on pathways    Has been on at least one previous Focused Labs project    Tech Lead Rotations    Tech leads are typically allocated to a project for at least 8+ months (or the duration   of the project, if it’s a shorter engagement).    Large (3+ pair) projects and projects that have a tech lead who is scheduled to   rotate will have an appointed secondary tech lead. The secondary tech lead will pair   with the tech lead, in order to gain context on both the role and on the project.    Becoming a Tech Lead for the first time    Talk to your manager about your interest in the role    Be appointed as a secondary tech lead on a project and shadow the current tech   lead    Secondary Tech Lead    This role is a specifically appointed developer who is a pair to the current tech lead    The purpose of the role is to:    Up skill a new tech lead by giving them the opportunity to learn from an   experienced tech lead on a project.    Transfer knowledge and context from an existing tech lead when they are   scheduled to rotate off of a project.    Future Ideas & Next Steps    Guidelines and metrics around measuring the technical success of   engagements    Additional tech lead training    Tech Lead4\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/8a424ee2-b1d7-41c3-a1f2-43160b949896_Why_we_do_what_we_do.pdf\n",
      "processing file: 8a424ee2-b1d7-41c3-a1f2-43160b949896_Why_we_do_what_we_do.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file 8a424ee2-b1d7-41c3-a1f2-43160b949896_Why_we_do_what_we_do.pdf with contents: Why we do what we do    Love your craft    Listen First    Learn Why    What is our culture    We build our interactions around collaboration    We deliver efficiently and fast    What defines our culture    The people    Daily Practices    Shared values around work output    our development approach & methodology     How we communicate    That we have clients    Our mission    What does it mean love your craft    I take enjoyment out of what I do    I stay current on the latest and greatest    You try to learn new things in your industry    Why we do what we do1⁉  \fYou can recognize bad craftsmanship    You improve your approach    You represent and showcase the value in quality    Why do we say craft  It makes it an art form    Crafts can be continuously improved    There are skills that are honed but never mastered    Sits outside of specific technologies    Love your craft and use the tools rather than the other way around    There's passion and dedication to quality.    I feel accountable for the output    What tools are integral to our culture    Pair Programming    Test driven development    CI/CD    Google    Why we do what we do2\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/94550ad9-5435-4814-9222-fa69e1074ee6_Pair_Retros.pdf\n",
      "processing file: 94550ad9-5435-4814-9222-fa69e1074ee6_Pair_Retros.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file 94550ad9-5435-4814-9222-fa69e1074ee6_Pair_Retros.pdf with contents: Pair Retros    What is a pair retro?  A pair retro is a short retrospective (usually around 5 minutes) held at the end of the day   with the person you’ve been pairing with. The purpose is to talk about how the day   went, reflect on what went well, and determine if there are ways the pair can collaborate   better in the future. It’s a good opportunity to get to know your teammate’s working style   and improve your future pairing sessions.    What should I talk about in a pair retro?    Times throughout the day when you felt things were going really well    “I felt like we were really in a groove after lunch - we crushed out that feature   and managed to get in that sweet refactoring”    “I liked that we took a break when we got stuck on that test - I felt a lot more   refreshed coming back, and we were able to get unstuck a lot faster”    “Today was really fun!”    Times when you felt like pairing could have been better    “When we were working on that story after lunch I felt like we were spinning   because neither of us were familiar with Spring Security. Next time I think we   should split for a bit and review the docs, so we can understand what’s going   on”    “I felt a bit behind when we were working on the front end code. Next time I’d   like to drive so I can get more familiar with that part of the codebase”    “I was really dragging in the middle of the afternoon, sorry if you felt like I wasn’t   fully present. I’ll suggest that we take a quick break next time”    Any questions you might have for your pair    Pair Retros1🦜  \f“I’m working on explaining complex technical solutions in a simpler way. Do you   have any feedback for me from the meeting earlier when I was explaining that   new system?”    “How do you feel today went?”    FAQs    Should pair retros be every day?    Ideally, yes! During pair retros, it's essential to engage in meaningful   conversations with your pair, even if you feel aren't any significant concerns to   address. These conversations provide an excellent opportunity to connect with   your pair and allow them to express their thoughts about how the day went. It's   a great way to reflect on what went well throughout the day and identify areas   where you can improve your collaboration in future pairing sessions.   Additionally, these conversations provide insight into your pair’s working style,   which can help you understand them better and optimize future pairing   sessions. So, it's highly recommended that you take advantage of every pair   retro session, even if you don't have any big concerns to address.    What if I don’t have any critical feedback for my pair?    It's okay to not always have critical feedback! Take a moment to see what could   have been improved, but if a pairing session went really well, that's great.   There's no need to force feedback just for the sake of finding something to   criticize. However, changing your perspective can sometimes be helpful when   thinking about feedback. We often think of pair feedback as simply \"critical\", but   it can also be a valuable tool for understanding each other's strengths and   desires for growth. By doing so, you can optimize your partnership and support   your pair in achieving their goals for growth.    If you and your pair were working in the physical world, building a   complicated structure and the plans were continuously in flux, and you were   collaborating on a physical task, what worked today and what didn’t work   today? If you were building a house, and your pair was holding the hammer   while you held the nail, what worked and what didn’t work for the two of   you? Would it be better for someone to mark where the nails should go   instead, and you use the nail and hammer? Do you want them to     Pair Retros2\fdemonstrate how they use a different type of tool? Is there anything about   how you worked together that could be changed to make things more   efficient / fun / engaging / simple?    Pair Retros3\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/a0922c1c-012c-445a-bd0c-17c5e380af70_Project_Rotations.pdf\n",
      "processing file: a0922c1c-012c-445a-bd0c-17c5e380af70_Project_Rotations.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file a0922c1c-012c-445a-bd0c-17c5e380af70_Project_Rotations.pdf with contents: Project Rotations    Critical tool to delivering high quality software over time    How we rotate between projects.    Why it is good for us    We want depth in software development not domains    Exposes ourselves to various points of view    Gain breadth, learn how to learn    Drop in anywhere and be productive    Keeps us from getting bored    FocusedLabs team cohesion    Keeps us from getting stuck    Shows we have a lot of great people    Chance for people on the team to take more responsibility     More flexibility during allocation cycles    Project Rotations1🌬  \fKeeps one project from having all engineers    Can go on vacations and turn off email    Loosely coupled, highly cohesive     Why it is good for clients    Multiple people have context, vacations don't halt work!    Makes hand off much easier    Forces client to not be reliant on Focused Labs    Makes the code base easier to hand off    Practice onboarding before clients are onboarded    Make production support easier    Keep the energy level up    Flexibility to increase / decrease burn    Adds resilience by building in the constant of change    Improves the code base    Product can outlast the team    Good for everyone!    Increases quality of codebase    Reduces bus count    Forces tribal knowledge to be codified    Reduces dependency on any one person    if you love something let it go    Anchors    Project Rotations2\fContext holder    Responsible for the long term success of the project    Why decisions were made?    Soft landing for clients as we rotate everyone else    Non-dictatorial position    Filling gaps    Project Rotations3\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/ac00bd07-b307-4a97-becc-0e79913831ba_2023_Strategy.pdf\n",
      "processing file: ac00bd07-b307-4a97-becc-0e79913831ba_2023_Strategy.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file ac00bd07-b307-4a97-becc-0e79913831ba_2023_Strategy.pdf with contents: 2023 Strategy    Thesis    Today Focused Labs has minimal market recognition outside of our existing   client base and past network. In order for the business to sustain itself in the   short term and grow in the long term the company needs a larger and more   reliable pipeline of new clients and projects. Creating a strong association of   our thought leadership with the Focused Labs logo will increase the   opportunity for collisions with potential clients, equip our sales team with a   stronger narrative for close, and attract top talent.    In order to establish ourselves as thought leaders we need a combination of   individual recognizable personalities, re-usable content (written or otherwise),   and consistency of presence in a variety of mediums.    A Vision for Thought Leadership  Thought leadership is a core part of our strategic vision for Focused Labs in becoming a   “badge of honor” that amazing people to seek to have on their resume. Practitioners   that spend time at Focused Labs should be proud to have Focused Labs as a part of   their professional work history, confident that it will open up incredible opportunities for   their career. In order for our peers and industry to share in celebrating that badge of   honer they first need to be aware of it. Our 2023 vision for thought leadership is all   about getting out there so that everyone knows who Focused Labs is and what are   thought leaders on.    First Goal    2023 Strategy1💡  🌟  \fAs a starting point, we need to focus on creating habitual behavior in publishing   content that expresses all the amazing things that we already are doing. Our high level   strategy is to categorize and deliberately target content at two distinct (but not mutually   exclusive) audiences: buyers and practitioners.    Practitioner Audience  We need Focused Labs to become a trusted source of high quality content for   practitioners who are looking to hone their craft. I personally think about sources like   Baeldung, Silicon Valley Product Group, or Martin Fowler’s blog as examples of   reputable and reliable sources of high quality content.    Some examples:    If I am looking to understand a particular coding pattern in the Spring framework   I will scroll past StackOverflow and Medium results and jump to the Baeldung   result first because I know it’s concise and accurate every time.     Perhaps I am looking for some additional reading to send to a client after a   conversation about iteratively evolving software architecture. Martin Fowler’s   blog is the first place I’m going to find supporting material.    Perhaps, my client isn’t familiar with writing or using Gherkin style acceptance   criteria. I send them this blog to read before we get together to pair on the first   set of stories for our backlog.    You identify that one of the sources of pain for your client company in adopting a   more agile and empowered team way of working is that communication between   the team and leadership is broken. You send this overview of how to write great   executive summaries from Reforge to your client to consider and then get   together to make a plan on next steps to improve communication on this team.    [need some design centric examples, help!] Design systems, Research best   practices, How to critique and evaluate interfaces etc.    While those examples set a pretty high bar, remember our first step is to create   habitual behavior. We can be thoughtful about areas of focus and excellence but   we don’t want that to be a blocker. Let’s not let the enemy of good be perfect.    2023 Strategy2\fContent Budgets    Starting on March 1st, 2023 each of our practices (Product, Design, Engineering,   DevOps, and Delivery Lead) will have monthly content budgets for their departments   to use in order to generate content. Directors will be accountable for making sure   that resources are allocated and content is produced but the expectation is that   individuals are responsible for creating the content itself.    Content Guide    We don't want to constrain creativity. At the same time a blank canvas can be a   difficult place to start. Below are some ideas to get the gears turning.      has put together a great guide to get you started on different forms and     voices of written content.    Who exactly are we writing this for?    Think about writing to your fellow Focused folks and to your future self. We   create some pretty incredible patterns, team dynamics, and solutions on every   project. Writing down interesting solutions may be something you or your peers   will find valuable on the next project!    Other practitioners of your craft. The goal is to share our skills out with the world.   We do some pretty incredible things when it comes to building software and we   can help other practitioners learn from what we do.    Other teams within a current client. When we help large enterprise clients   establish better ways of working, more effective software testing strategies, or   develop outcome oriented roadmaps you better believe there are other teams   within the organization struggling with similar issues.    Yourself. Creating a brand and a history of content is something that you can   reference and carry with you throughout your career.    What exactly are we supposed to be writing about?    2023 Strategy3@Justin Williams\fIt's really easy to convince yourself that an idea might not be all that interesting   or interesting to everyone. Beware of getting blocked. Seek feedback from your   peers.    Thought Leadership isn’t always novel or revolutionary. Rather it can be a   unique repacking of a few ideas or the implementation of a theory in practice.    Write about what you are doing today, it's already quite extraordinary.    Think about the things we do that are differentiating. Our practices may seem   routine because we do them all the time here at Focused Labs, but are they   industry standard? Think about the ah-ha moments that you have had with   clients and teams. Tell a story.    Ask yourself about what things you find yourself having to introduce to most new   clients. Let’s create a toolbox full of getting started with Focused Labs   supporting materials.    Start small. Our initial goal is to create habitual behavior. Default to quantity over   quality, then evaluate quality.    What types of content are we aiming for?    Written form content has the lowest barrier to entry and is the best place to start   forming habitual behavior. We strongly encourage everyone to start there.    We are open to other types of content and don’t want to constrain creativity. If   you have another medium that you are interested in meet with your Director and   to make a case and expect feedback.    ✍ Writing Guide    Buyer Audience  Content specifically targeted at potential buyers needs to align with our GTM   strategy and to appeal to leaders who having buying power over our services. The   primary goal of this narrative is for Focused leadership to present themselves as   innovative peers that our buyers crave to have on their team. Focused Labs   leadership team members will primarily be responsible for creating this content.    2023 Strategy4\fOur aim is to:    Have vision on the future of our industry and paint a picture of how a customer   fits into that vision.    Amplify what the company has accomplished for other customers to create and   realize that vision    Tie it all together with why Focused Labs is the right partner to help the next   customer achieve that vision.    Starting Point (Q1)    Focus on content related to what we are currently good at, back fill content for   success to date.    Building highly productive software teams in a traditional IT environment.    PODs - building a marketplace platform to enable a new business model    Building strong remote culture with the transparency leadership needs    Internal Case study on the efficacy of our remote culture. Start to shape   our offerings as a \"remote first\" playbook.    Getting organizations \"un-stuck\" on long standing problems    Ford Marketplace - Event Storm reorganization of teams and unblocking   new product development    Design and document a repeatable publication flow. Where (LI, dev.to, sub-  stack, etc...), how (documented instructions, shared FL accounts, syndication,   canonicalization). Repeatable by GSA staff.    Types of Content    Case studies, conference talks, co-presenting with clients, webinars. Public   facing, real time and conversational content.    2023 Strategy5\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/bafc416e-9abb-4496-ac43-343895b2021e_The_Denver_Office.pdf\n",
      "processing file: bafc416e-9abb-4496-ac43-343895b2021e_The_Denver_Office.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file bafc416e-9abb-4496-ac43-343895b2021e_The_Denver_Office.pdf with contents: The Denver Office    Focused Labs @ Venture X - LoDo   1800 Wazee St   3rd floor   Denver, CO 80202    https://gph.is/2O30OSQ    🚪Entering the Building  The Focused Labs office is located on the 3rd floor in office 356/357. See the floorplan at the end of the page for a visual.     If it is your first time visiting the office you can speak with security on the first floor and they will badge you up. Just say   you’re headed to Venture X.    🚊Travel    Public transit - we will be reimbursing your travel in full. We ask that you submit expenses at the end of each month for any   given month using the expensing process.     Driving - we will be reimbursing your parking. We suggest using Spot Hero when able to. Otherwise you can park in the building   lot.     Biking - in order to use the bike room, you need to specify that you need access when filling out your badge access form.     The Denver Office1🚪Entering the Building🚊Travel🆔 Badges❕Lost your badge? 🐶 Bringing your Dog to the office 🐶🍪 Food & Other Amenities\u0000 Gym access🍟 Snacks program🚚 Food Delivery\u0000 Visitors 💸 Dairy Block Discounts 🐮 Milk Market📬 Mail and Packages📥 Incoming Mail/Packages📤 Outgoing mail/packages🖨 Printing🗺 Map of Venture X Floor🍽 Colorado Supper Club🧭  ⚠  🆔  ❕  \f🆔 Badges  Badges will be provided to employees who visit the office at least   weekly. All other employees will visit as guests and will receive   temporary access. To receive a badge for the Denver office, please   reach out to help@focusedlabs.io for the appropriate forms.     ❕Lost your badge?   Please visit the front desk of Venture X if you lost your   badge. You can also email help@ and we can help with   the process.     🐶 Bringing your Dog to the office 🐶  Venture X is a dog friendly office. In order to bring in your pup, you will need to sign off on some forms at the front desk. Please be   responsible and only bring in your dog if you know it gets along well with other 4-legged and 2-legged (and everything in-between)   friends.     🍪 Food & Other Amenities  \u0000 Gym access  The Venture X office has a gym available for use by all members. You will need to sign the gym waiver, which you will receive with   the badge form. If you need the gym waiver, please visit the Venture X front desk, or email help@.     The gym is located on the 2nd floor, to get there you will need to use the side elevators or use the Blake street entrance.    🍟 Snacks program  There is coffee, cold brew, kombucha and water available in the shared kitchen.     There are light snacks available in our office.     🚚 Food Delivery  The Food Court on the first floor will deliver up to Venture X, just use this link or scan the QR code    https://www.toasttab.com/denver-milk-market-2/order-and-  pay/VentureX/    \u0000 Visitors   If not meeting your guest on the first floor, please let them know to tell security they’re visiting Venture X so they can be let up to the   third floor.    Once at Venture X, guests can either sign in at the iPad to notify their host that they’ve arrived, or you can just meet them by the   front desk.     The Denver Office2\fVisitors do not receive temporary badges and must stick with their host to navigate. If they leave the building and need to come   back, they’ll just have security badge them up again.     💸 Dairy Block Discounts     🐮 Milk Market  You can use the discount code VTX for 10% off your order    📬 Mail and Packages  📥 Incoming Mail/Packages  All mail and packages should be shipped to the address below.   All incoming mail/packages will be brought to the mail room.     Our mailbox is E18. Packages will be left on the table.    Your Name    Focused Labs   1800 Wazee St   Suite 300   Denver, CO 80202    📤 Outgoing mail/packages  Outgoing mail can be dropped off with the front desk.     For outgoing packages, you must schedule a pickup with your   carrier and bring it to the front desk.    🖨 Printing  You can print for free using the Venture X printers. Please visit the Venture X front desk and the team will help get you set up.     🗺 Map of Venture X Floor    The Denver Office3📦  \f🍽 Colorado Supper Club  On the fourth Wednesday of each month, we will be hosting a dinner out at local team members’ favorite dining haunts.     Date    Restaurant    Family Friendly?    February 22    White Pie - Uptown, Denver    \u0000 yes    March 22    The Plimoth - City Park, Denver    \u0000 no    Steuben’s - Uptown, Denver    Abejas - Golden    \u0000 yes    \u0000 no    SuperMegaBien - RINO, Denver    \u0000 yes    April 26    May 24    June 28    July 26    August 23    September 27    October 25    November 15    The Denver Office4\u0000  \u0000  \u0000  \fDate    Restaurant    Family Friendly?    December 20    Restaurant Ideas    Brasserie Brixton    West 29th    My Brother’s Bar    Rioja    Stella    Seoul Korean BBQ    Kobe An    La Diabla Pozole y Mezcal    The Denver Office5\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/c6c651e3-2d90-480e-aa54-9915022f5e7a_Pairing.pdf\n",
      "processing file: c6c651e3-2d90-480e-aa54-9915022f5e7a_Pairing.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file c6c651e3-2d90-480e-aa54-9915022f5e7a_Pairing.pdf with contents: Pairing    Core Collaboration Practice    Pairing as a practice has existed in the industry for a while and means many things to   many people. This article is super in-depth, https://martinfowler.com/articles/on-pair-  programming.html.     This notion page covers what pairing means to Focused Labs and why it is one of our   core practices.    Pairing1What is pairing to us?It's our defaultWhat is it NOT?Code ReviewsOccasionally for hard problemsWhy default to pairing?How to be a good pair?All around good advice:If you're the confident type...If you're the introverted or struggles-with-impostor-syndrome type...Tools!Additional resources on pairing\u0000  \fWhat is pairing to us?  It's our default    It's not just for blockers anymore!     Pairing here consists of two equal partners writing code together: one computer, but two   of everything else (monitors, keyboards & people). After stand, each team determines   their pairs for the day. We try to rotate our pairs daily unless something that requires a   lot of context is in-flight. Throughout the day, we strive to help each other grow our skills  and share knowledge about the codebase and tools we're using.    While pairing is our default, it's a flexible practice. Sometimes, you wind up with an odd-  numbered team, so you solo for a day. Sometimes, you might be on a one-pair team,   and rotation isn't an issue. We might adjust the practice to current conditions ⛈, but it's   a baseline practice here and something you should expect to spend a fair amount of   time doing.     Pairing isn't only, a practice, it's also a skill. Being a good pair involves being able to   participate in constant feedback and collaboration, for more tips on being a good pair,   keep on reading!    What is it NOT?  Code Reviews  Code review is a hard practice for little return. We have found pairing to be far more   effective, especially for long term sustainability.    Occasionally for hard problems    Pairing is a skill and like any skill, you can only get better at it by doing it.    Pairing2\fIf you are working long term on a significant amount of code that is rote, your   codebase is probably missing an abstraction. A pair will help you find the   appropriate abstractions to avoid this in the future.    Why default to pairing?    The Martin Fowler article linked to above offers a whole host of reasons that   pairing can be beneficial. Here are a few reasons that we like to pair:    💗 Pairing can improve quality of life as a dev. Sometimes writing code solo can be   fun and feel productive, but sometimes... it can go sideways. We've been there: rabbit-  holed for hours on something that was essentially a typo \u0000. The recipient of a PR   review filled with comments on using const vs let ...while leaving the architecture   change you'd like feedback on unmentioned. Receiving feedback on a feature that   you'd spent hours on, and feeling personally attacked or like an impostor 🥊. Pairing is   great for preventing too-deep-in-the-weeds problems, because you've got someone   there to pull you out, and a second set of eyes to see what you can't. You can get   meaningful feedback on what you're writing from someone who has shared context and   shared concerns. Finally, because responsibility for the code is distributed across the   team, we can still have pride in crafting something well, without that feeling of ownership   becoming possessive or defensive. Pairing distributes the burden and shares the joys.    \u0000 Pairing is great for building teams. By working side-by-side with someone,   you're encouraged to reconcile their way of thinking with your own. Getting out of your   own head like this can strengthen everyone's understanding of the task at hand, and   fosters in-depth communication. By switching pairs frequently, no one person holds all   the context, and knowledge is distributed across the team. In the event that you're   onboarding to a new project, or have less experience in a given language or platform,   pairing offers valuable learning opportunities beyond what the docs can provide. And   as the more experienced pair, it offers a chance to learn how to communicate your   knowledge plainly (which is a valuable skill for consultants)  also, nothing cements what   you think you know, like explaining it to someone else 😈.     Pairing3☝  \f✨ Pairing makes for better code. The act of talking through any given feature,   optimizes the code in a few ways. Communicating often requires clarifying your own   thought process and getting immediate feedback on assumptions and understanding.   In making sure that the code that we're pairing on is clear to each other, the code   becomes more readable for others and our future selves. Given a diverse team, people   come from different backgrounds (whether education, workplace, language preference   or just personality), and that diversity gets passed along to the code's style and   approach. Plus, two sets of eyes means fewer bugs 🐛    🦚 Pairing is just good practice.  There are a few     Fosters empathy    You involve people in the design rather than the output    Fast feedback loops    less possessiveness makes introducing client devs to the codebase easier    How to be a good pair?    We only get the benefits of pairing when we're being the best pair we can be.    All around good advice:    Listen first    Take breaks: frequent breaks are key to regaining focus, feeling better and being   able to think on something in your own way    If you're the confident type...    Let your pair to have equal time on the keyboard, and encourage them to drive if   they're hesitant to take the keyboard    Pairing4👐  \fIf you're the person with more context/experience, bring your pair up to speed and   don't just forge ahead without them    If you're the introverted or struggles-with-impostor-syndrome   type...    Speak up: If you're feeling lost or out of context, don't be afraid to raise it. Calling   out confusing code helps to make sure that it's written more clearly.     [ADD MORE]    Tools!  Tuple    Screen    Additional resources on pairing    Austin's Built In Chicago interview    Some work station ideas:   https://www.nomachetejuggling.com/2011/08/25/mechanics-of-good-pairing/    http://llewellynfalco.blogspot.com/2014/06/llewellyns-strong-style-pairing.html?m=1    There's a conference about how to make pairing more inclusive:   https://pearconf.splashthat.com/    Pairing5\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/c94b9664-d316-4bbf-bfaa-d6f11c0ad7ab_Product__Design_Lunch.pdf\n",
      "processing file: c94b9664-d316-4bbf-bfaa-d6f11c0ad7ab_Product__Design_Lunch.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file c94b9664-d316-4bbf-bfaa-d6f11c0ad7ab_Product__Design_Lunch.pdf with contents: Product / Design Lunch    Topic & Activity Ideas  **Put your name ahead of your idea so we know who to coordinate with               Cars vs. Stakeboards Revisited (a different take on the classic)         Thought Leadership Content Creation    We generated ideas of content to be created, in any preferred medium (blog,   Youtube video, podcast, etc) in Miro    ✍ Writing Guide     Role-based Core Competencies    When you start working on a piece of content, drop a title, short description, your   name, and status in the table below. We’ll use this table to collaborate and avoid   duplicative work. If someone started something you’re excited about and the status   isn’t done, ping them to see if you can collaborate!    👾 Non-obvious ways to come up with product and feature ideas    Title    Description    Name    Status    Product / Design Lunch1Justin Williams - Science of Creativity DiscussionShahed - 🪴 Digital GardeningAnne - Foundational Facilitation Techniques (Module 2 AJ & Smart Course)🎨  \fTitle    Description    Name    Status    DoorDash Giftcard Codes    Date    1/18/23    1/18/23    1/18/23    2/15/23    2/15/23    2/15/23    3/15/23    3/15/23    4/26/23    4/26/23    5/24/23    5/24/23    5/24/23    Code ($25 per code)    Name    NAAWK9M9YSMZXJ2V    Karlie    NAAWKPBCPNVAEP43    Justin W    NAAWKSUZ66S34AU6    Annie M    NAAWK7J8GE9EN433    Mary M    NAAWKBEL3LWEMLKJ    Justin    NAAWKTERJQ6L295C    Lindsey    NAAWKYFLZPHATTYJ    Justin    NAAWKYG36ATL29RN    NAAWKQ7ZJCY8VVJ3    Mary    Seth    NAAWK485B5FKP9KL    Annie    NAAWKTZYQPWZU9SG Annie    NAAWKWQ2QCN2ZA7D John    NAAWKTNRRL4S9L2P    Seth    NAAWKNYBG3SR9TMP    NAAWK89LP2NWMNA4    NAAWKFGL8WJHGG83    NAAWKZ6KUTNVL2XT    NAAWKAK5YLYDQ3LR    NAAWK2RX2UJL5G56    NAAWKBCFTJ2H8EPW    NAAWKHPL55KH5WKG    NAAWKNGJ76AJE66F    NAAWKBAKKH8GREVZ    NAAWKGYXPCAH8RK4    Product / Design Lunch2\fCode ($25 per code)    Name    Date    NAAWKEH43WP559W6    NAAWKE985XD7BLPN    NAAWKCH3XRRUCGSX    NAAWKTY8PN3NSBYB    NAAWKQZXWEH92DTS    NAAWKQ7N5MMFXBJ2    Monthly Agenda/Notes    [Month 2023]    Check-in  [check-in question or prompt]    Thought Leadership Check-in    Discussion(s) / Activities  May 2023    Check-in  [check-in question or prompt]    Thought Leadership Check-in    Discussion(s) / Activities  April 2023    Check-in  [check-in question or prompt]    Thought Leadership Check-in    Product / Design Lunch3\fDiscussion(s) / Activities     - Foundational Facilitation Techniques (Module 2 AJ & Smart     Course)  March 2023    Check-in    How’s it going?    Any pressing thoughts.    Discussion(s) / Activities    Digital Gardening: a tool to think effectively. - Shahed    February 2023    Check-in  Fishbowl Game    Discussion(s) / Activities    Brainstorm Thought Leadership Content Creation    Miro Board    January 2023    Discussion(s) / Activities    Goals of this Gathering - Lindsey    Science of Creativity Discussion - Justin    🎸 Creativity Jam    Product / Design Lunch4@Annie McDonald\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/de95e697-2d3c-4bf7-af90-8cca954d7410_Software_Development.pdf\n",
      "processing file: de95e697-2d3c-4bf7-af90-8cca954d7410_Software_Development.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file de95e697-2d3c-4bf7-af90-8cca954d7410_Software_Development.pdf with contents: Software Development    Our core development principles and practices are inspired by Extreme Programming,   which is an agile methodology designed to improve software quality and reduce the cost   of change. A deep dive into this can be found in Kent Beck's XP Explained. In this book,   Beck talks a lot about three main things, but in a lot more detail:    Values: The roots of the things we like & don't like in a situation. Important, but   high-level enough that they might be misconstrued (e.g. Communication, Simplicity,   Feedback, Courage, Respect)     Practices: What you do. Practices are visible and concrete, but ... might not   directly connect to a higher-level value (e.g., pairing, meeting, writing   documentation)  Principles: \"Principles are domain-specific guidelines for life.\" Principles connect   your values to concrete actions. Examples of principles include: Humanity,   Economics, Mutual Benefit, Self-Similarity, Improvement, Diversity, Reflection, Flow,   Opportunity, Redundancy, Failure, Quality, Baby Steps,    Core Values + Engineering    👂 Listen first - we are experts when it comes to software, but life long learners in   the domain of our customers. We listen, collaborate, and iterate closely with our   clients.    ❓ Learn why - we are deeply invested in the outcomes of our clients and apply   our expertise to make wise technology decisions with them.  🧶 Love your craft - we love programming and the craft of software engineering.    Our Practices    Software Development1🛠  \f\u0000 Pairing    🚦 TDD     🌬 Project Rotations    ⚓ Anchors    🦜 Pair Retros    🦺 Tech Lead    Engineering Events  \u0000 Code Crushing Committee (CCC)    📕 Book Club     Resources  XP Onboarding Deck    Tech Retro    Stripe Certification     📖 The Library     \u0000 Engineering Interview Process     WIP  These are topics that need a notion page or an update.    Tech retros    Introduction to XP    Managing technical debt    Pair retros    Project rotations    Software Development2\fArchived    🚦 TDD (old)    \u0000 Pairing and Rotations • 04.06.22    Software Development3\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/e4fd509a-4447-4a60-bafa-ac85cfd40797_So_you_want_to_be_a_TPIer.pdf\n",
      "processing file: e4fd509a-4447-4a60-bafa-ac85cfd40797_So_you_want_to_be_a_TPIer.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file e4fd509a-4447-4a60-bafa-ac85cfd40797_So_you_want_to_be_a_TPIer.pdf with contents: So you want to be a TPIer    So, what is the TPI?    Focus on Empathy, Aptitude, and Communication    Our Technical Pairing Interview is the first gate to working with Focused Labs. Right now   we use an almost exact replica of an interview from a previous company. It's important   that we understand why we replicated this interview and what the goal is.    We use this exercise as our first interview because it is objective, repeatable, canned, and   has a consistent scoring system. The exercise tests a candidate's ability to implement an   object oriented solution, test drive that solution, communicate about the code in that   solution, and be empathetic to the boundaries we set. This interview is a great way to get   a quick leading indicator of success and is a lot of fun!    Who should consider learning the TPI?    A developer who is excellent at TDD and Pairing, and can demonstrate the value of   these practices to a candidate who might not be familiar with them    Someone who is comfortable and confident in their ability to accurately and quickly   make a determination on weather a candidate is worth investing in a full day interview    Someone who has the time and willingness to learn the exercise - it typically takes   between 15 - 20 hours to be fully onboarded and ready to run TPIs on your own!    Process  1. Reach out to a current screener to kick off the process. You can also ping     “@screeners” in Slack and that’ll get to us.    2. Learning the Exercise     a. You need to memorize the happy path of the exercise and be able to type the     code quickly and accurately (maybe in around 15 minutes with minimal mistakes).     So you want to be a TPIer1🐘  \fi. This includes a fair number of IntelliJ shortcuts to learn, in order to maximize     speed and visual clarity for the candidate. Consider if you can do the following   without touching your mouse:     1. Generate a constructor    2. Automatically complete an if statement or for loop block    3. Move a few lines of code in a file upwards or downwards    4. Switch your cursor focus from the file on the left to the file on the right    5. Open and close the test window or project window    b. Additionally you’ll need to memorize the talk track for the exercise.     c. Some resources    i. Video Recording of a Perfect TPI With Cece and Luke:     https://drive.google.com/file/d/1YND9e7iL3SDQvTNXX67OlNO2fOI6Ixz8/view    3. Practice TPIs - This usually goes in a few phases    a. Happy path TPIs with current screeners, where we’ll be perfect candidates and     you practice.     b. Not happy path TPIs with current screeners, where we’ll mimic candidates of     varying quality.    4. Observe real world TPIs    a. This is where you’ll learn to score along with the screener giving the interview,     and you’ll discuss.    5. Start conducting TPIs    a. At the beginning, you’ll do this while being observed by a screener, who will help     you score or even score for you.    6. Graduation! You’ll now be a full screener and we’ll add you to the Calendly rotation.    7. Profit    🦄 Pairing Interview    So you want to be a TPIer2\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/e67cd5c9-c8ea-4ce2-a028-8b8c2fcc3e77_Anchors.pdf\n",
      "processing file: e67cd5c9-c8ea-4ce2-a028-8b8c2fcc3e77_Anchors.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file e67cd5c9-c8ea-4ce2-a028-8b8c2fcc3e77_Anchors.pdf with contents: Anchors    ⚓ Anchor Meeting    Anchors are expected to...    Keep leadership informed of the health of their team, client, and project    Project status    Practices status    Client happiness    Allocation needs    Communicate upcoming milestones    Communicate risks    Have a longer rotation on a project or with a client    Help a team arrive at and stick to our best practices    Push the team to continuously improve on practices    If there is no PM, there are additional expectations    Manage the backlog of work    Facilitate IPM    Ensure retros/demos are happening    What is an anchor?    An experienced XP practitioner who can represent how and why we approach   building software in the way that we do    Anchors1⚓  \fSomeone who can understand the health of the team, where there is room for   improvement, and help the team achieve that improvement    Someone who is generally allocated to a project longer than over developers, in   order to maintain context and client relationships    Some who can start a new project with a new client    Keeping track of technology, leading the tech practice, following best practices    Mentor - ramping up people's context, understanding their roles, making sure they   have context, are growing in their roles    Why do we need anchors?    For us - Consistency in practices and team dynamics    For clients - confidence - don't need to always rehash what we're doing, what's   already been done    Relationships are hard and take time    Trust by association - easier to bring in new folks to the client if there's someone   there the client already trusts    Helps us maintain context as well    Allows us to rotate the non-anchors, someone there to keep that context    What are the responsibilities?    Know the tech stack - know enough to be able to ramp new folks into it    Managing the backlog    Regularly meet with the client    Keeper of the rituals - running IPMs    Communicating staffing needs    Coordinating the work    Understand upcoming work - scope    Anchors2\fKeep an eye on scope - make sure team is focused on the project, doesn't get off   track    Communication with client - keep them informed about if we're going to miss/make   deadlines    Understanding actual business needs - product direction    Making sure the team is following best tech practices    Delegating!!!    What are not the responsibilities    Doing everything themselves    Training everyone on the tech stack    People management - giving performance reviews, etc    Not an eng manager    Not an architect - not there to design everything    Lead, don't dictate    Not on call 24/7    You don't own all of the success or failures of the team    Keeping all the context themselves - makes it too difficult to roll off    How do you know when you're the anchor?    It should be designated by leadership    Rubric    Item    Description    Status Notes    Anchors3\fItem    Description    Status Notes    Overall project  status    Client happiness    Testing practices    Upcoming  milestones    Risks    Wins    How is the client feeling about progress? Are you  communicating with them enough to know?    How confident are you in production deploys? Is the team  having conversations around testing?    Upcoming releases, team changes, etc    One sentence or less    One sentence or less    Allocation needs    Do you need more/less engineers? PMs? Design?    Technical debt    Velocity and  volatility    Release cadence    Look for consistence over time, ratio of bugs to stories to  chores    Pairing    Is the team pairing? Pairing with clients?    Client enablement  (if applicable)    Test coverage    How confident are you in production deploys? Is the team having conversations   around testing?    Velocity and volatility    Is it consistent?    Allocations    Do you have the right number of engineers? PM? Design?    Pairing    Is your team pairing consistently? Switching pairs regularly? If there are clients,   are you pairing with them?    Anchors4\fOverall project status    Client happiness    How is the client feeling about progress? Are you communicating with them   enough to know?    ⚓ Anchor Meeting    Anchors5\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "./data/ff157be3-a2d2-4bfc-bffa-6627abb59a79_2023_Strategy.pdf\n",
      "processing file: ff157be3-a2d2-4bfc-bffa-6627abb59a79_2023_Strategy.pdf\n",
      "file cleaned of newlines, double spaces, and semicolons\n",
      "embedding file ff157be3-a2d2-4bfc-bffa-6627abb59a79_2023_Strategy.pdf with contents: 2023 Strategy    Thesis    Today Focused Labs has minimal market recognition outside of our existing   client base and past network. In order for the business to sustain itself in the   short term and grow in the long term the company needs a larger and more   reliable pipeline of new clients and projects. Creating a strong association of   our thought leadership with the Focused Labs logo will increase the   opportunity for collisions with potential clients, equip our sales team with a   stronger narrative for close, and attract top talent.    In order to establish ourselves as thought leaders we need a combination of   individual recognizable personalities, re-usable content (written or otherwise),   and consistency of presence in a variety of mediums.    A Vision for Thought Leadership  Thought leadership is a core part of our strategic vision for Focused Labs in becoming a   “badge of honor” that amazing people to seek to have on their resume. Practitioners   that spend time at Focused Labs should be proud to have Focused Labs as a part of   their professional work history, confident that it will open up incredible opportunities for   their career. In order for our peers and industry to share in celebrating that badge of   honer they first need to be aware of it. Our 2023 vision for thought leadership is all   about getting out there so that everyone knows who Focused Labs is and what are   thought leaders on.    First Goal    2023 Strategy1💡  🌟  \fAs a starting point, we need to focus on creating habitual behavior in publishing   content that expresses all the amazing things that we already are doing. Our high level   strategy is to categorize and deliberately target content at two distinct (but not mutually   exclusive) audiences: buyers and practitioners.    Practitioner Audience  We need Focused Labs to become a trusted source of high quality content for   practitioners who are looking to hone their craft. I personally think about sources like   Baeldung, Silicon Valley Product Group, or Martin Fowler’s blog as examples of   reputable and reliable sources of high quality content.    Some examples:    If I am looking to understand a particular coding pattern in the Spring framework   I will scroll past StackOverflow and Medium results and jump to the Baeldung   result first because I know it’s concise and accurate every time.     Perhaps I am looking for some additional reading to send to a client after a   conversation about iteratively evolving software architecture. Martin Fowler’s   blog is the first place I’m going to find supporting material.    Perhaps, my client isn’t familiar with writing or using Gherkin style acceptance   criteria. I send them this blog to read before we get together to pair on the first   set of stories for our backlog.    You identify that one of the sources of pain for your client company in adopting a   more agile and empowered team way of working is that communication between   the team and leadership is broken. You send this overview of how to write great   executive summaries from Reforge to your client to consider and then get   together to make a plan on next steps to improve communication on this team.    [need some design centric examples, help!] Design systems, Research best   practices, How to critique and evaluate interfaces etc.    While those examples set a pretty high bar, remember our first step is to create   habitual behavior. We can be thoughtful about areas of focus and excellence but   we don’t want that to be a blocker. Let’s not let the enemy of good be perfect.    2023 Strategy2\fContent Budgets    Starting on March 1st, 2023 each of our practices (Product, Design, Engineering,   DevOps, and Delivery Lead) will have monthly content budgets for their departments   to use in order to generate content. Directors will be accountable for making sure   that resources are allocated and content is produced but the expectation is that   individuals are responsible for creating the content itself.    Content Guide    We don't want to constrain creativity. At the same time a blank canvas can be a   difficult place to start. Below are some ideas to get the gears turning.      has put together a great guide to get you started on different forms and     voices of written content.    Who exactly are we writing this for?    Think about writing to your fellow Focused folks and to your future self. We   create some pretty incredible patterns, team dynamics, and solutions on every   project. Writing down interesting solutions may be something you or your peers   will find valuable on the next project!    Other practitioners of your craft. The goal is to share our skills out with the world.   We do some pretty incredible things when it comes to building software and we   can help other practitioners learn from what we do.    Other teams within a current client. When we help large enterprise clients   establish better ways of working, more effective software testing strategies, or   develop outcome oriented roadmaps you better believe there are other teams   within the organization struggling with similar issues.    Yourself. Creating a brand and a history of content is something that you can   reference and carry with you throughout your career.    What exactly are we supposed to be writing about?    2023 Strategy3@Justin Williams\fIt's really easy to convince yourself that an idea might not be all that interesting   or interesting to everyone. Beware of getting blocked. Seek feedback from your   peers.    Thought Leadership isn’t always novel or revolutionary. Rather it can be a   unique repacking of a few ideas or the implementation of a theory in practice.    Write about what you are doing today, it's already quite extraordinary.    Think about the things we do that are differentiating. Our practices may seem   routine because we do them all the time here at Focused Labs, but are they   industry standard? Think about the ah-ha moments that you have had with   clients and teams. Tell a story.    Ask yourself about what things you find yourself having to introduce to most new   clients. Let’s create a toolbox full of getting started with Focused Labs   supporting materials.    Start small. Our initial goal is to create habitual behavior. Default to quantity over   quality, then evaluate quality.    What types of content are we aiming for?    Written form content has the lowest barrier to entry and is the best place to start   forming habitual behavior. We strongly encourage everyone to start there.    We are open to other types of content and don’t want to constrain creativity. If   you have another medium that you are interested in meet with your Director and   to make a case and expect feedback.    ✍ Writing Guide    Buyer Audience  Content specifically targeted at potential buyers needs to align with our GTM   strategy and to appeal to leaders who having buying power over our services. The   primary goal of this narrative is for Focused leadership to present themselves as   innovative peers that our buyers crave to have on their team. Focused Labs   leadership team members will primarily be responsible for creating this content.    2023 Strategy4\fOur aim is to:    Have vision on the future of our industry and paint a picture of how a customer   fits into that vision.    Amplify what the company has accomplished for other customers to create and   realize that vision    Tie it all together with why Focused Labs is the right partner to help the next   customer achieve that vision.    Starting Point (Q1)    Focus on content related to what we are currently good at, back fill content for   success to date.    Building highly productive software teams in a traditional IT environment.    PODs - building a marketplace platform to enable a new business model    Building strong remote culture with the transparency leadership needs    Internal Case study on the efficacy of our remote culture. Start to shape   our offerings as a \"remote first\" playbook.    Getting organizations \"un-stuck\" on long standing problems    Ford Marketplace - Event Storm reorganization of teams and unblocking   new product development    Design and document a repeatable publication flow. Where (LI, dev.to, sub-  stack, etc...), how (documented instructions, shared FL accounts, syndication,   canonicalization). Repeatable by GSA staff.    Types of Content    Case studies, conference talks, co-presenting with clients, webinars. Public   facing, real time and conversational content.    2023 Strategy5\f\n",
      "Starting the embedding process...\n",
      "Calling OpenAi API for embeddings...\n",
      "Done. Embedding received...\n",
      "Finished with embedding process\n",
      "Loading vectors into Redis\n",
      "Finished loading vectors into Redis\n",
      "CPU times: user 393 ms, sys: 132 ms, total: 525 ms\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This step takes about 5 minutes\n",
    "\n",
    "# Initialise tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Process each PDF file and prepare for embedding\n",
    "for pdf_file in pdf_files:\n",
    "    \n",
    "    pdf_path = os.path.join(data_dir,pdf_file)\n",
    "    print(pdf_path)\n",
    "    \n",
    "    # Extract the raw text from each PDF using textract\n",
    "    text = textract.process(pdf_path, method='pdfminer')\n",
    "    \n",
    "    # Chunk each document, embed the contents and load to Redis\n",
    "    handle_file_string((pdf_file,text.decode(\"utf-8\")),tokenizer,redis_client,VECTOR_FIELD_NAME,INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22aff597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-01T00:56:45.896919Z",
     "start_time": "2023-06-01T00:56:45.881599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'90'"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that our docs have been inserted\n",
    "redis_client.ft(INDEX_NAME).info()['num_docs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12cb6e",
   "metadata": {},
   "source": [
    "## Make it a product\n",
    "\n",
    "Now we can test that our search works as intended by:\n",
    "- Querying our data in Redis using semantic search and verifying results\n",
    "- Adding a step to pass the results to GPT-3 for summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e921ac96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:55:59.995003Z",
     "start_time": "2023-05-31T23:55:59.955605Z"
    }
   },
   "outputs": [],
   "source": [
    "from database import get_redis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cb9dfacf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:56:04.692197Z",
     "start_time": "2023-05-31T23:56:02.090104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Querying Redis *****\n",
      "Original Query: when is the 2023 Chicago IRL scheduled for?\n",
      "Embedded Query: b'!\\xfb<;\\'\\x07\\xc2\\xbc\\xd3\\x08\\x87\\xbb\\xe9\\xd6!;\\xd8|g\\xbc\\xb1\\xefg<\\xfd\\x87$\\xbd\\x12\\x9eQ\\xbb\\xb2\\x87\\x0c\\xbd\\xc6\\x80\\xa1\\xbc\\x81\\x8c\\x0e=Dy\\x86;\\xc4\\x8e\\x83\\xbb\\xf9\\xfd\\xe1\\xb9\\xbfW\\x84\\xbb\\xc5\\xab\\x9b\\xbc\\xb34\\xc9;4\\x8f\\xa7\\xbc\\xd23\\x81;\"\\x18\\xd5;\\xd4\\xb5C<h\\xec\\x1e;}J^<\\xae\\xb5\\xb7\\xbc\\x8fy\\x1e:o\\x15\\xbc\\xba\\x88\\x8db;\\x8fy\\x9e\\xbc.;\\x90<\\xd7_\\xcf\\xbc\\xdcN\\xbc<@\\xa71\\xbc4\\xd79:6\\xc9\\xd7\\xbc\\xc1\\xd9\\xc6\\xbc\\xcd\\xf1P\\xbd\\xd9\\\\\\x1e<\\xff\\xcc\\x85\\xbc\\xe9\\x8e\\x8f:\\xa9\\x19\\x0e\\xb9\\xb6\\x96\\xc2<Tx};x\\x13_<b\\xd5\\xe8\\xbc\\xbc2\\xec\\xbc\\x07\\xae\\x10=Y\\x1f\\xd8;]a\\x88\\xba\\x14\\xbbi\\xbc\\x7f\\x8f?<9\\xc6\\xa6<\\x18:{<\\x91\\x06\\x92\\xbc\\x9f\\xf3!\\xbd\\x16eu<_+]\\xbce\\xd2\\xb7\\xbc)\\xdcG<\\xbah\\x97;Z\\xf4]\\xbb.\\xcb4<\\x83\\x9eu\\xbc\\x7f\\xe2\\x82\\xbc\\xf4\\x89\\x01=W\\xe5\\xa7<-f\\n;\\xf7pn\\xbc\\x962\\xe0<\\x93\\xdb\\x97\\xbb\\xf1o\\x9a\\xbc\\x8b\\xef[<\\xe6\\xe4\\x03=\\xfe4a<\\xbew\\xcd\\xbc.\\xcb\\xb4<:\\x9b\\xac\\xbc\\xd6\\xa7a:\\x10\\x1c\\x8f\\xbc\\x97\\xa2\\xbb<\\x8e\\xa4\\x18\\xbc\\x1eQ\\xb1<\\xb8\\x93\\x11\\xbc\\xc9*\\xad\\xbc6Y|<\\x17\\xd5P<T;\\x9c<\\xfc\\xb2\\x9e<;\\xb8D<9sc\\xbc\\xad(D\\xba\\xd4m1<\\xbfW\\x84<\\xdf\\xb05\\xb9\\xcc\\x1c\\xcb<\\x14s\\xd7\\xbc\\xe2Z\\xc1:\\x9e\\x13\\xeb\\xbc\\xe7I\\xae;3\\xba!;6\\x1c\\x1b\\xbc2\\x02\\xb4<o\\x15\\xbc;T;\\x1c\\xbc\\xf1\\xac{\\xbc\\xaf\\xdd\\x80\\xbc\\xfd\\xcf\\xb6\\xbc\\r\\x02\\xa8\\xba\\xc4\\xf3\\xad<3g^;]a\\x88<\\x03\\x94)\\xbc N\\x00=\\x93\\x93\\x05=\\xf73\\r\\xbd\\xf6\\x9bh<2\\x024\\xbc\\xb34\\xc9\\xba\\x02\\xbf\\xa3;lk\\xb0\\xbb\\xc0t\\x9c\\xbc5\\xac\\xbf<A_\\x9f<]\\xe6\\xfb<\\x16\\xb8\\xb8\\xbc\\nX\\x9c;p\\xc2x\\xbc0\\x10\\x96\\xbc%\\xc2\\xe0\\xbc\\xa7\\x81\\xe9\\xbaX\\x02@<\\x97O\\xf8;\\xa3r\\xb3\\xbb\\xd0\\xe3\\xee;\\x01\\xdfl;u\\xb1\\xe5\\xbb\\xabS><\\xbc\\xa2\\xc7\\xbcr\\xbf\\xc7<!\\xa8\\xf9\\xbc\\x0b-\"\\xbcq\\xeaA\\xbc\\xde\\x93\\x1d;N\\x94\\xc1\\xbc\\xd0\\xa6\\r;)\\x04\\x91\\xbc\\x10\\x1c\\x8f<\\xab\\xa6\\x81<\\x01\\xdfl\\xbbH@\\xaa<8\\xa9\\x8e\\xbbp\\xcd\\xa9<\\xbfW\\x84\\xbc3g^\\xbc?\\xc7\\xfa< \\x8ba<Z\\xff\\x8e<\\xb9\\xf8\\xbb\\xbb\\x83\\x9e\\xf5<\\xc8U\\xa7\\xbb\\xdd#B\\xbc\\x17\\xe0\\x81<\\xe7\\x91\\xc0\\xbca\\x00c:\\xdc\\xbe\\x17<\\xb7k\\xc8<\\xd2pb<\\xa2U\\x1b=\\xb9\\xf8;<\\xd8|\\xe7;J]B\\xbb\\xd1{\\x93;E&\\xc3<\\xcaGE\\xbd\\xf9\\x08\\x93;\\xa9Vo\\xb9M\\x07\\xce<\\x04L\\x97<\\xaf%\\x13\\xbc\\xf6\\x0b\\xc4\\xbcg|C\\xbc)\\x04\\x91<\\xa2\\x92|<\\xf9\\xc0\\x00=\\xdb1\\xa4\\xbb6d\\xad\\xbb\\x02\\xb4r;WJ\\xd2<\\x01\\xdfl\\xbc\\xacpV\\xbc\\xf0R\\x82\\xbc\\x91\\x06\\x12=L\\xa2#<\\x8e\\\\\\x06<\\x12\\xf1\\x94;(w\\x1d\\xbf\\x04\\xf9\\xd3\\xbc\\xdc\\xfb\\xf8<?\\xd2\\xab\\xbb\\xd1\\xc3\\xa5:\\x92#*=\\xa4\\xd7\\xdd\\xbb\\x1a\\xd2\\x9f;\\x10\\x1c\\x8f\\xbc\\xeer\\xcb<\\xa1\\xbd\\xf6<\\xac\\x00{<\\xe6,\\x16<\\xce\\x0e\\xe9\\xbc\\xde@Z<U\\xc8\\x0f\\xbd\\xday6=\\xbc\\xf5\\x8a<\\xec-j\\xbbv\\x86\\xeb;\\xb8#6\\xbcm\\x18m\\xbb\\x1b\\xa7\\xa5\\xb6\\xba \\x85\\xbc\\x01\\xa2\\x0b\\xbc\\x81d\\xc5<\\x02\\xb4\\xf2;R\\xae(\\xbd6d\\xad\\xbc\\xdf\\xb0\\xb5\\xbc\\x92#*\\xbc!\\xa8\\xf9<!\\xfb\\xbc;\\xbe\\xe7\\xa8\\xbc\\xc9r\\xbf<X\\x02\\xc0\\xbc\\xd4m\\xb1\\xbccE\\xc4<\\x01\\xdfl<\\xe0 \\x11=\\r\\xf7\\xf6\\xbc\\xfc\\xb2\\x1e<\\xc0,\\n\\xbc\\x83a\\x94<Z\\xff\\x8e:`S&=m#\\x9e<9~\\x94;v\\xd9\\xae:\\xb9@\\xce\\xbc\\xd4m1<?\\x1a\\xbe\\xba\\x93\\xdb\\x97\\xbct\\xdc_\\xbb\\x9a\\xbc\\xa2<\\xe8f\\xc6\\xbc\\xbc\\xf5\\x8a<{\\x10\\xae<\\xff\\x14\\x189\\x96\\x85#\\xbcb\\xd5\\xe8\\xbb\\xef\\x9a\\x94<\\xb0\\x8a=\\xbd\\x86S\\xb2\\xbc\\xa9\\xc6\\xca<<\\x1d\\xef:Dy\\x86;2\\x024<\\xbc\\xa2\\xc7;\\xd3P\\x19<\\x19\\xaaV\\xbb\\xc9\\x1f\\xfc<\\xb1_\\xc3\\xbc\\xf3a8\\xbcZ\\x8f3\\xbb]a\\x88:#\\xf8\\x8b<\\xcb\\xb7 =\\x92k\\xbc\\xbb\\xbd\\x07\\xf2;\\xba\\xb0)\\xbb\\xd2\\xe0\\xbd\\xbcOL/<<p\\xb2\\xbb\\x1b\\xef7<\\x80\\xac\\xd7\\xbc\\x8c\\xcf\\x12\\xbd\\xa4*!\\xbc\\x99\\x94Y;\\x0b-\"<wI\\x8a;\\xbc\\xf5\\x8a<\\xdd#\\xc2\\xbb]\\xa9\\x9a\\xbcap\\xbe\\xba0\\xbdR\\xbb\\xba\\x15\\xd4\\xbc\\xd7\\xcf*<W\\xe5\\xa7;\\x17\\xe0\\x81\\xbc,\\xeb\\xfd:\\xb6\\xde\\xd4\\xbb<p\\xb2<P!\\xb58dm\\r=\\x88\\x98\\x93;\\x85\\x9b\\xc4\\xbc\\xbb=\\x1d;\\x0c\\xe5\\x0f;#\\x88\\xb0\\xbc#@\\x9e\\xbc\\x9cI\\x16<\\xac\\xc3\\x99\\xbc\\xa2\\x9d\\xad\\xbb\\xdf\\xb0\\xb5\\xbc\\xe1\\xad\\x84\\xbc\\xc6\\x80!\\xbc\\xbfW\\x84;\\x1e\\t\\x9f<\\x12\\xf1\\x14\\xbc \\x8b\\xe1<\\x86\\xb8\\\\\\xbcE&\\xc3<m#\\x1e\\xbbn\\x88\\xc8\\xbb\\x12\\xa9\\x02\\xba\\t\\xe8@<\\x94h\\x0b<*i\\xbb\\xbb\\xfe\\xa4\\xbc<I5\\xf9\\xbb\\xa5G9<\\xac\\x00\\xfb<lk\\xb0\\xbc\\x80\\xff\\x9a<r\\x12\\x8b<ut\\x04=Rf\\x96\\xbckN\\x98\\xbc\\xec-\\xea\\xbaZ\\xf4\\xdd\\xbc\\xa4\\xd7\\xdd;\\xfa\\x1a\\xfa:\\xd8?\\x86\\xbbo\\xb0\\x11\\xbc\\x8f\\xb6\\xff\\xbc\\xc6up\\xbcG`s<\\xe0\\xcd\\xcd;\\x8e\\xe1\\xf9\\xba\\xad(D\\xbb\\xdc\\xbe\\x97\\xbc\\xd7\\xcf\\xaa\\xbc\\x8d4\\xbd;\\x1f\\xb6[\\xbc\\xfb\\x95\\x86\\xbc\\x10\\x1c\\x8f<\\x8c_7\\xbdm#\\x9e\\xba\\xcb\\xff\\xb2\\xbc\\xfe4a:N\\x94\\xc1;\\xef\\xd7u\\xbb\\xa6\\xac\\xe3\\xbb\\xc1!\\xd9<\\xc8\\x02d<\\xa7D\\x88\\xbb\\x8c\\x17\\xa5<\\x9f;\\xb4\\xbcO\\xf9k\\xbcj&O\\xbc8\\xa9\\x0e\\xbc\\x8e\\\\\\x06\\xbc\\xba\\xb0\\xa9<\\xeb\\x1b\\x83:\\xf3\\xfc\\x8d\\xba(/\\x8b<b\\xd5h\\xbc\\x02\\xbf\\xa3:\\xc4\\xf3\\xad;\\xf2\\x8c\\xb2;\\xf1\\'\\x88<\\x86\\xb8\\xdc;J]B\\xbb\\xebXd<\\xa7\\xd4,\\xbc\\x8c\\x17\\xa5<\\x0c\\xda\\xde<\\xef\\xd7u\\xbc\\x85\\x9bD<\\xf9\\x08\\x13<\\x16e\\xf5<\\xa6\\xb7\\x94\\xbb\\xf9\\xfda<0\\x05e<r\\x12\\x8b<g\\x17\\x19\\xbc\\x11\\x11^\\xbc0\\xbdR\\xbc;\\x00\\xd7;j&\\xcf<2\\x024<e7b\\xba\\xdc\\xbe\\x17\\xbc\\xce\\xa9>\\xbb\\xbd\\xca\\x90\\xbc\\xb9\\xf8;\\xba\\xf7p\\xee\\xbc\\x80\\xf4\\xe9<\\xb2\\x171\\xbc/\\xa0\\xba<\\x10\\x1c\\x0f\\xbc\\xad\\x98\\x9f\\xbc\\xe0\\x15\\xe0;C\\xa4\\x00:\\xc2\\x01\\x90<\\xba\\xb0\\xa9\\xbc\\x84s\\xfb\\xbat\\x04)\\xbb\\x8eQU<(ll<\\xddv\\x85\\xbc\\x02\\xbf#<\\x8f\\xb6\\x7f\\xbb\\x89\\xb5\\xab\\xbb;\\x0b\\x88:\\x06\\x86\\xc7\\xbbO\\xbc\\n=X\\xba-=\\xaf\\xdd\\x00\\xbd\\xcf\\xd1\\x87\\xbc\\x9f\\xab\\x0f<\\xfd\\x17\\xc9<T\\xf3\\x89<{\\x10\\xae<\\x02\\xbf\\xa3\\xbc#\\xf8\\x8b;\\x1fnI;N\\xdcS=r\\x12\\x0b:xf\\xa2<\"\\x18U<!CO=J]B<FN\\x0c<dm\\x8d\\xbb\\xb7k\\xc8<\\x8f\\xc10:\\xfbB\\xc3\\xbb\\x80\\xff\\x1a<h\\xec\\x1e\\xbd4G\\x95\\xba\\x18:\\xfb\\xbb\\xf1\\'\\x88<\\xc9\\x1f\\xfc:n\\xed\\xf2\\xbc\\x83a\\x14\\xbc\\xce\\x19\\x9a\\xbc\\rJ\\xba<\\xc5\\xa0j<4\\x8f\\'<\\x92k<<9\\xc6\\xa6<PiG<<p2\\xbc\\x11\\x11^\\xba\\x07\\xf6\"\\xbc]\\xf1,\\xba\\xac\\x00{;\\x80\\xacW\\xbc\\xd1\\x0b8\\xbcTx\\xfd\\xbc\\xaa6\\xa6\\xbc\\xcf~D\\xbbz\\xa0R<\\x0fG\\x89<b\\x98\\x07\\xbc1u@\\xbde\\x8a%;\\xd3P\\x99<,\\xf6\\xae<\\xf9\\xc0\\x00\\xbdo\\x15<\\xbc\\xf0G\\xd1<X\\xba\\xad\\xbc\\x1d)h\\xbc\\t0S<\\xe8\\x1e4<p\\xcd);\\rJ:;\\xa3r3\\xbc\\xcf6\\xb2<\\xdeK\\x8b<{\\x10.\\xbb\\xb9\\xf8;\\xbb\\xd8|\\xe7:\\xde\\xd0\\xfe<)L\\xa3\\xbc`S&\\xbdK2\\xc8\\xbc\\xc2I\\xa2;\\xf0GQ<a\\xc3\\x01<\\xe2\\xa2\\xd3\\xbc\\xce\\x19\\x1a=Z\\x8f\\xb3<\\x0c\\x92L;\\xc0t\\x1c\\xbds/\\xa3\\xbc\\xf4\\x19&\\xbc6\\xd4\\x88<\\x93\\xd0f<\\xa8\\xf1\\xc4\\xbc\\xba\\x15T;\\x9f\\xf3\\xa1;<\\x1d\\xef;~*\\x95\\xba\\xd4m1\\xbc\\xb0B\\xab9>\\xaab\\xbc\\x86\\xc3\\r\\xbc\\xe9\\x8e\\x8f\\xbc3r\\x0f\\xbd\\x94\\xf8\\xaf\\xbc\\x83\\x0e\\xd1=w\\xf6F<ui\\xd3<iQ\\xc9<\\xc78\\x0f\\xbc96\\x02<v\\xd9\\xae\\xb9\"k\\x18\\xbd\\xc7\\xe5\\xcb\\xbb\\x85\\x9b\\xc4\\xbc)\\xdcG;\\xf73\\x8d:\\xd2\\xe0\\xbd;d\\x1a\\xca;\"k\\x98<7\\x81E<\\nMk\\xba\\xec-j\\xbc\\xd5\\xd2[<@7V<b\\xd5h\\xbc\\x07\\xae\\x10\\xbc\\x07[\\xcd\\xbc\\x83a\\x14=*i\\xbb<\\x8e\\xa4\\x98\\xbc\\xab\\x0b,<G#\\x12\\xbc\\xafm\\xa59\\x8a\\x1a\\xd6\\xbc\\xde\\x93\\x1d\\xbcB|\\xb7<\\xc4\\xf3-<\\xc9\\x1f\\xfc;\\t;\\x84\\xbc\\xf2\\x8c\\xb2;\\xebc\\x95;\\x9bt\\x90\\xbb(l\\xec<\\xf6\\xa6\\x99<;S\\x9a\\xbaa\\x00c\\xbb\\xdd#\\xc2;\\xb2\\xc4m\\xbc\\xdeK\\x0b\\xbbT\\xe8\\xd8\\xbcZ\\xff\\x8e\\xbc\\x84s\\xfb<\\xe6\\xe4\\x83\\xbcq\\x97\\xfe\\xbb\\xc1!\\xd9<k\\xde<<\\xec\\x80-\\xbd\\x00z\\xc2; \\x8b\\xe1\\xbcLZ\\x91<\\xc9*\\xad\\xbc\\xe4\\x9f\\xa2\\xbcrZ\\x1d\\xbcx\\x1e\\x10\\xbd\\xcd9\\xe3\\xbc\\x04L\\x97\\xbc=E\\xb8;?\\x8a\\x99\\xbb\\x9df\\xae\\xbc\\xff\\x14\\x98\\xbc\\x15\\x90o\\xbb\\xb0B+\\xbc\\xe6i\\xf7\\xbc\\x18E\\xac\\xbc\\x03\\x94)<\\xcd\\xfc\\x01\\xbd\\xee\\x02\\xf0\\xbc\\xb5\\xe9\\x85;\\x03\\x94)<<\\x1do\\xbc\\xad\\xe0\\xb1</\\xa0\\xba;\\x15S\\x0e<\\xb8\\xdb\\xa3<m\\x18m;\\xef*9\\xbd\\xa7\\x81\\xe9\\xbb)A\\xf2\\xbb\\xd9Q\\xed;D\\xb6\\xe7<\\xba]\\xe6;\\x1e\\t\\x9f\\xbc\\x9b\\xd9\\xba;\\xb8\\xdb\\xa3<0\\xc8\\x03<\\x16e\\xf5\\xbbt\\x04\\xa9<\\xf0R\\x02<\\xff\\x14\\x98<\\x90&\\xdb:|u\\xd8<\\xe2\\x12/<1-.\\xbb`\\x9b\\xb8;\\x98w\\xc1\\xbag\\xcf\\x06\\xbb\\xbfW\\x84\\xbc\\x96\\xea\\xcd\\xbb\\x96=\\x91:\\xe9\\xd6\\xa1<FN\\x8c;Yg\\xea\\xba[d\\xb9\\xbc\\x98\\xbf\\xd3\\xba\\xd9\\\\\\x9e<N\\x94\\xc1\\xbb\\x81\\x8c\\x8e;\\x9d\\xae\\xc0\\xbc\\x16\\xb8\\xb8:T\\xe8X<\\xe6!e<\\xdc\\xbe\\x97\\xbb\\xcd\\xfc\\x01\\xbd\\x80\\xff\\x1a\\xbb\\xc5\\xab\\x1b\\xbc\\xfe\\xec\\xce\\xbc\\x19b\\xc4<I\\xa5T<\\xf0\\xb7\\xac\\xba\\x9e\\x83F;\\xe1\\xea\\xe5\\xbbq\\x97\\xfe\\xbbo]N\\xbc\\x97\\xa2\\xbb<\\x08\\x83\\x96\\xbc\\xc4\\x83\\xd2;\\xe9\\xd6!\\xbbO\\xf9k\\xbb3\\xba\\xa1\\xba\\xa6d\\xd1\\xbcwI\\x8a;\\xfcj\\x0c<\\x89\\xb5+;\\xd6B7\\xbc\\xcea\\xac\\xbb\\xfc\\xef\\xff\\xba\\xef\\xe2\\xa6<Y*\\x89\\xbc>bP\\xbc4G\\x95\\xbc\\xa0\\xa0\\xde\\xbczX\\xc0;\\x8a\\xd2\\xc3<\\xd6\\xb2\\x12=,\\xf6\\xae\\xbb\\x8fy\\x9e<\\x88\\x8db;1\\xe5\\x1b\\xbc\\xfd\\x17\\xc9\\xba\\x07\\xae\\x10\\xbcz\\xe8\\xe4\\xbcp=\\x05\\xbd9\\xc6\\xa6<\\xc4\\xf3\\xad<\\x12\\xa9\\x02=\\xb8\\xdb\\xa3\\xbc)\\x04\\x91<t\\x04)\\xbb8\\x9e\\xdd<\\xfe4a\\xbb\\x97Z\\xa9\\xbc\\x90\\xdeH<\\x04\\x89x\\xba\\xa8\\xa92\\xbc\\xde\\xdb\\xaf\\xbb\\xc6u\\xf0\\xb9\\xcc\\x1cK\\xbc\\x12\\xa9\\x02\\xbc2\\x02\\xb4\\xbc\\xebc\\x15;6Y|;xf\\xa2<#@\\x1e\\xbc\\x87\\xe0%\\xbdy\\xcbL\\xbc\\x01\\xa2\\x0b;\\xb2|\\xdb;\\xe1\\x85;;O\\xbc\\x8a\\xbca\\xb8\\xd0\\xbbMw\\xa9<\\x00\\xea\\x1d<ut\\x04=6d\\xad;\\x17\\x8d>\\xbc\\xf2D\\xa0\\xbc\\x08\\x83\\x96<\\xf3\\xf1\\\\\\xbc\\xc9*-\\xbc|uX;\\x9c\\x01\\x84\\xbc\\xba \\x85\\xbc\\x9cI\\x16<D\\xb6g<p\\xc2\\xf8<f\\xa7\\xbd<x[\\xf1;q\\x97\\xfe<\\xb2\\xc4\\xed;9\\x0e9=\\xc4\\xcb\\xe4\\xbcG#\\x92\\xbbC\\xec\\x92;\\x13\\xc6\\x9a\\xbc\\x88P\\x81:Pi\\xc7\\xbcP\\xb1\\xd9\\xbc\\xce\\x0e\\xe9\\xbc\\x9cI\\x96\\xbb\\xd1S\\xca\\xbb#\\x880\\xbc9~\\x94<\\xbfL\\xd3\\xbc:+\\xd1\\xbb\\x80\\xff\\x1a\\xbc\\x18E,\\xbc\\xdb\\x96N;G#\\x92<\\xc4\\x8e\\x03=\\x04\\x89\\xf8<>\\xb5\\x13<\\xb6\\x96\\xc2;\\x04L\\x97\\xbc\\xef\\xe2\\xa6<[\\x1c\\'<Pi\\xc7<\\xa1u\\xe4<\\xc78\\x8f\\xbcK\\x85\\x0b\\xbc\\xb0\\x8a=<r\\xbf\\xc7;$]6\\xbdPiG\\xbd\\x11\\xc9\\xcb:u\\xbc\\x16=\\x93\\xdb\\x97<\\x81\\xd4\\xa0\\xbc\\xfe4\\xe1\\xbc\\'\\x07\\xc2:\\xb4\\\\\\x12=.\\xcb\\xb4\\xbb\\xaf%\\x93;Kz\\xda\\xbb\\xa8\\xf1\\xc4\\xbb96\\x82<\\x84s\\xfb;\\x17\\xd5\\xd0\\xbc\\x9bt\\x90;\\x81dE<\\xb4\\tO<\\x1b\\xa7%\\xbc\\xf4\\xd1\\x13\\xbc_+\\xdd\\xbc\\x002\\xb09,\\xeb}<\\xba]\\xe6;\\x92\\xb3N<\\xdeK\\x8b;\\x04\\xf9S\\xbc\\x18E,;\\x90\\xdeH\\xbcDy\\x86\\xbc\\x00\\xea\\x1d;\\xc5X\\xd8<\\x19b\\xc4\\xbc\\xe4\\x94\\xf1;\\xaa\\xe3\\xe2\\xbcn\\xedr\\xbcp=\\x85;\\x02\\xb4\\xf2:\\xd0\\x9b\\xdc\\xbb\\x7f\\xd7Q\\xbc\\xc5X\\xd8\\xbc\\xd1{\\x13\\xbb\\xbd\\xca\\x90<\\r\\xba\\x15<CQ=;rZ\\x1d\\xbbb\\xd5h\\xbc\\xd3\\x8dz\\xbc\\x97\\x12\\x97\\xbc.\\xcb\\xb4:\\xc9\\x1f\\xfc;\\xab\\x0b\\xac\\xbc\\xdc\\xfbx;\\xbc\\xf5\\x8a\\xba\\xad(D;\\xee\\xba\\xdd\\xbb\\x8e\\xe1\\xf9;d\\xaan<lC\\xe7;uiS\\xbb\\xb51\\x98\\xbc.;\\x10\\xbc9~\\x14\\xbb\\xafm\\xa5<G\\xb36\\xbc\\x901\\x8c\\xbctL;\\xbcz\\xf3\\x95\\xb8&\\x97\\xe6<\\xbb=\\x9d<\\x8bB\\x9f\\xbckN\\x98\\xb9k\\xde\\xbc<0\\x10\\x96\\xbb\\xee\\xc5\\x0e\\xbc\\xe4\\xe74<\\xac{\\x07=\\x01\\xa2\\x8b<\\xf8(\\xdc;\\x84\\xc6\\xbe9\\xabS>\\xbd\\xb7C\\x7f<\\x82\\xf1\\xb8\\xbc\\xa4\\xe2\\x8e<\\x129\\'=X\\xba-\\xbc\\xc78\\x0f=\\x10\\x1c\\x0f\\xbc\\xcbo\\x8e<\\xdc\\xfbx<\\xa3\\x02X\\xbaZ\\xff\\x0e\\xbc\\xb34\\xc9<A\\x0c\\xdc\\xbbw\\xae\\xb4\\xbc\\xe6!\\xe5\\xbc\\xe6,\\x96\\xbcv\\x91\\x1c\\xbb\\x002\\xb0\\xbc\\x8e\\xec\\xaa<a\\xb8\\xd0\\xba\\x98\\xbfS\\xbc\\x0e\\xd7-\\xbc\\x98\\xbf\\xd3<v\\x86\\xeb\\xbaG`s\\xbcM\\xbf\\xbb;j\\xc1\\xa4\\xbc\\x05\\xd9\\x8a\\xbc\\x83\\x0eQ\\xbd\\x0bu4\\xbd\\x1b\\xef\\xb7\\xb9^VW\\xbc\\xa18\\x83=\\x15\\x9b <o\\xa5`\\xbc\\x1a7\\xca\\xbc)\\x04\\x91\\xbcQ\\x91\\x90;LZ\\x91;:+\\xd1\\xbb6\\x1c\\x1b<\\x8d\\x87\\x00=;Hi\\xbc\\x97O\\xf8\\xba\\xe9\\x8e\\x0f=o\\xa5`\\xbc\\xe1\\xad\\x84<B4%<*i;<<p2=%\\xc2\\xe0;r\\xbf\\xc7\\xbb4\\x84\\xf6<\\x94\\xf8\\xaf\\xbb)Ar<v\\x86\\xeb;\\xe4\\x9f\"=\\x80\\xb7\\x88\\xbb\\x1f\\xb6\\xdb<\\xf7\\xc31;B|7<\\\\\\xd4\\x14;N\\xdcS\\xbc,\\xeb\\xfd\\xbcut\\x04<4G\\x95\\xbc\\xfcj\\x8c\\xbc\\xa0\\x10\\xba\\xba\\xaa+\\xf5\\xb9\\xf4\\x89\\x81\\xbcO\\xbc\\x8a<v!\\xc1\\xbb\\xf1\\xac{\\xba\\xe1\\xea\\xe5\\xbbcE\\xc4\\xbc\\xd5\\x8aI\\xbbv\\x86\\xeb\\xbb\\x16eu\\xbc\\xd3\\x98\\xab\\xbc96\\x02=|-\\xc6\\xbc\\xc0t\\x9c<\\x84\\xc6><4G\\x95<.\\xcb4\\xbc\\xf3\\xf1\\\\\\xbc\\xca\\x9a\\x08<\\x0c\"\\xf1\\xbc\\x80\\xff\\x1a\\xbcf\\xa7\\xbd<\\xfa%\\xab;~r\\xa7<WJR\\xbcx[q;Y\\xd7\\xc5\\xbb#}\\xff\\xbc\\x9f\\xab\\x8f;\\x18E,;\\xe3\\x82\\x8a\\xbc\\xa0\\x10\\xba<\\x89%\\x07;\\xbc\\xa2\\xc7\\xbc\\\\\\x8c\\x02\\xbc,\\xf6.\\xbc\\x81\\xc9\\xef\\xbc\\xb5\\xc1\\xbc\\xbb\\xfd\\x17\\xc9;\\x9aLG\\xbco\\xb0\\x91\\xbc\\xa2\\x9d\\xad\\xbc\\x0c\"\\xf1;)\\x04\\x91\\xbc\\rr\\x83\\xbc\\x8e\\\\\\x06<\\x12\\xf1\\x14\\xbc\\xbf\\x9f\\x96;\\xbd\\xca\\x90<\\x89bh>\\xe7>};\\x7f\\xd7\\xd1;\\xc0\\xbc.<\\xb0\\xfa\\x98\\xbc\\x1a\\xd2\\x1f<\\xa4\\xe2\\x0e=\\xa2\\xe5?<\\xfb\\x95\\x86\\xbc\\xb5y\\xaa;\\xfd?\\x92\\xbc\\xfb\\x8aU<\\x0f\\xcc\\xfc\\xbc\\xe9\\xd6\\xa1:\\x0b\\xbd\\xc6;\\'\\x07B<I\\xa5T\\xbc\\x88\\x98\\x13\\xbd7\\x81\\xc5\\xbcv\\x86\\xeb;\\x16eu\\xbb\\xdcN<<Dy\\x06\\xbc/X\\xa8\\xbb\\x1d\\xe1\\xd5<g|C<\\x00zB;a\\x00\\xe3:\\xd8\\x87\\x18\\xbc\\xc3\\xd6\\x95<\\xbdZ\\xb5\\xbal\\xb3B;Ygj<\\x95\\x15\\xc8<\\xa0\\x10:\\xbc\\xf4\\xd1\\x13\\xbcEnU;P\\xb1Y\\xbca\\xc3\\x81<FN\\x0c=\\x14\\xbbi\\xbcN/\\x17;\\x16\\x00\\xcb<2\\x92X\\xbco\\xa5\\xe0\\xbc\\x96z\\xf2;\\x92#*\\xbc$\\x15\\xa4\\xbcZ<p;\\x13\\x0e\\xad\\xbb\\xb34\\xc9\\xbc_6\\x0e\\xbd`\\x9b8=ZG!=%\\xc2\\xe0<\\x93\\x93\\x05\\xbd{\\x05\\xfd<\\xf73\\x8d\\xbc\\xc4\\x8e\\x83\\xbb\\xc4\\x8e\\x83\\xbcw>Y\\xbc\\xb6\\xde\\xd4<6d\\xad\\xbb\\xae\\xfd\\xc9:0\\x10\\x96\\xbb)L#<Z\\xff\\x8e\\xba\\x8e\\\\\\x06=\\x99$\\xfe:\\xe5\\xbc:;\\xd3\\x8dz<\\x1fnI\\xbcU\\xa0F\\xbc\\x9a\\xbc\\xa2\\xbc\\x962\\xe0\\xbb\\xa6\\xac\\xe3\\xbcq\\x97~=\\xbc\\xf5\\n<\\x87\\xe0\\xa5<I5\\xf9<\\x92k\\xbc\\xbb\\x90&\\xdb;(w\\x1d=\\xc9*\\xad\\xbc\\xe9\\x8e\\x0f<\\xfa\\xdd\\x98\\xbcm#\\x1e=D\\xb6\\xe7;UX\\xb4\\xbcj\\xc1\\xa4\\xbb\\xbd\\x12\\xa3<\\xf7{\\x9f\\xbcO\\xbc\\n\\xbc\\x04\\x89\\xf8\\xbcz\\xe8d\\xbbjy\\x12\\xbck\\x96\\xaa<5\\xff\\x02=dm\\r;\\n\\xa0\\xae\\xba4\\x8f\\xa7;i\\t7=\\x9f\\xe8p<\\xd3\\x08\\x07\\xbd\\xbc\\xf5\\x8a\\xbc\"\\x18\\xd5\\xbb?\\x1a\\xbe<r\\x07Z\\xbb\\x8c\\xcf\\x92<\\x95\\x15\\xc8\\xbcb\\x98\\x07\\xbc\\\\\\x8c\\x02\\xbd4\\x8f\\'<l\\xfbT<S\\xcb@<\\xa4*!<+!)\\xbc{\\x05\\xfd\\xbc1\\xda\\xea\\xb9\\xb3\\xec6\\xbc]9\\xbf\\xbb\\x9f\\xf3\\xa1\\xbc\\xdeK\\x0b\\xbcYgj\\xbc\\xe6,\\x16\\xbc:+Q\\xbd\\x98\\xca\\x84\\xbc\\xf7{\\x1f\\xbc\\x81dE\\xbc\\xcd\\xfc\\x01\\xbd\\x8fy\\x9e\\xbb\\xc5c\\t9e\\xd27<\\xc6\\x80\\xa1\\xbb\\xe3/G<O\\x04\\x9d;OL\\xaf<\\xac\\xc3\\x19\\xbd\\x1e\\x99\\xc3\\xbb\\xd3\\x98\\xab\\xbc\\x96\\xeaM:K\\x85\\x0b\\xb7|-F\\xbc\\x1a\\xd2\\x1f\\xbd\\xb3\\xa4$<_+]\\xbc\\xfa\\xdd\\x98;\\xd8?\\x06\\xbc,\\xf6\\xae\\xbc\\xff\\xcc\\x85\\xbc \\x8ba<\\xde\\x93\\x9d\\xbc\\xf3\\xf1\\\\\\xbc\\xba]\\xe6\\xbb4G\\x15=\\x88\\x98\\x13\\xbc`S\\xa6;6Y\\xfc\\xbc\\x9e\\x13\\xeb\\xbckN\\x18=Z\\x8f\\xb3\\xbc\\x15S\\x8e<\\x88\\x98\\x13<o\\xa5\\xe0\\xbb\\xc2\\xf6^\\xbd\\xb1\\xef\\xe7;^\\xc62\\xbe\\xac{\\x87<\\xf0\\xb7,=\\rr\\x03\\xbd\\x89\\xb5\\xab<\\x00zB\\xbc1\\x9d\\t=G\\xb36\\xbc\\x0fG\\x89\\xbc\\xf9\\xc0\\x80\\xbc\\x04L\\x17<S\\x13\\xd3;\\xcb\\xff\\xb2\\xbc\\r\\xba\\x15\\xbc9sc\\xba\\xde@\\xda<p\\x85\\x17\\xbc\\xef\\xe2&=5<\\xe4\\xbb\\x18\\xfd\\x19\\xba9\\x0e\\xb9<\\x94\\xa5\\xec\\xbc\\xe1\\x85;<Y*\\x89<\\xe1\\xeae\\xbc\\x1c\\x17\\x01;\\x8e\\\\\\x06\\xbd\\xea\\xf3\\xb9\\xbb\\xa8\\xf1D<\\xedU\\xb3\\xbc\\xe1\\xad\\x84\\xbb\\xed\\xe5\\xd7\\xb9c\\xfd1=\\xf1\\xac{:N\\xe7\\x04<($Z\\xbcW\\x9d\\x15\\xbb<\\x1d\\xef\\xbb\\x1c\\xc4\\xbd\\xbc\\x00\\xea\\x1d=F\\x8bm:\\xeb\\x1b\\x83<\\xf4\\x89\\x01\\xbc\\x19bD\\xbcq\\xeaA\\xbd\\xb7\\x06\\x9e<\\x7f\\x8f?:\\xd3\\x8d\\xfa\\xba}\\x02\\xcc\\xbb\\xd8?\\x06\\xb8|uX<2JF\\xbd\\xa4\\xe2\\x8e;\\x16e\\xf5\\xbaRf\\x96<\\xaa\\xe3\\xe2<N$\\xe6:\\xee\\xba]\\xbc\\xc7\\xe5\\xcb\\xbb\\xc2\\x01\\x10\\xbcF\\x8b\\xed\\xbc*\\xf9_\\xbc\\xe2\\x12/<\\x97O\\xf8\\xbc\\xd8\\x87\\x98\\xbb\\xddk\\xd4\\xbc\\x8bB\\x1f\\xba\\x9df\\xae;\\x829K\\xbb\\x1b\\xef\\xb7<E&C<\\x18\\xfd\\x19\\xbc\\xe1\\xad\\x04;|\\xe53\\xbb\\xaa+\\xf5;I\\xb0\\x85\\xbc\\x1b_\\x93\\xbb\\x8b\\xa7\\xc9<\\xf1\\x1c\\xd7<3\\xafp;<( \\xbc\\x8c\\x17%=\\x94\\xf8\\xaf\\xbc^\\x0e\\xc5:\\xeb\\x1b\\x83<\\x08\\x83\\x16\\xbc\\x17\\xd5P\\xbb\\x15\\x9b\\xa0<\\x84~\\xac\\xbc\\xe0\\xcdM:\\xf7pn<\\xbf\\x04\\xc1\\xbb\\xf7\\xc31\\xbb\\xcc\\x1cK\\xbcxf\\xa2<\\xf1o\\x1a<\\xf1o\\x9a;\\x901\\x8c<b\\xd5\\xe8\\xbb\\xab\\x9bP\\xbdw\\xae\\xb4<\\x8eQ\\xd5\\xbb\\xed\\x9d\\xc5\\xba\\xbah\\x17\\xbc\\x80\\xff\\x1a<\\xfd\\x17\\xc9:\\xf0\\x8fc\\xbcui\\xd3<U\\xc8\\x8f<\\xe1\\xad\\x84;/X\\xa8\\xbc`\\x0b\\x94\\xbc\\x0e\\xd7-<\\x0f\\xcc\\xfc;\\x9b\\xd9\\xba;\\x88\\x98\\x13<]\\xe6\\xfb\\xba\\x9e\\xd6\\t;:\\x9b\\xac<6Y|\\xbb\\x02\\xbf\\xa3<\\x93\\x88T\\xbb\\xba]\\xe6:\\xf0R\\x82\\xba\\xaf\\xdd\\x80\\xbc\\xdf\\xb0\\xb5\\xbc\\xd4\\xb5\\xc3\\xbdF\\x96\\x1e\\xbd*\\xf9_<9s\\xe3<4\\x84v<\\x19\\x1a\\xb2<\\x98wA;\\x0c\\xe5\\x8f<[d\\xb9\\xbc\\x81d\\xc5<\"\\x18\\xd5;\\xdfh\\xa3\\xbcYgj9\\xb8\\xdb\\xa3<\\xdcN<=\\xd0\\xa6\\x8d;\\x18\\xb5\\x07<\\xf3\\xfc\\x8d\\xbc\\x1f\\xc1\\x8c\\xbb_+\\xdd<\\x01\\x97Z\\xbb\\xde\\xd0\\xfe\\xbbh\\xa4\\x0c<\\xc5c\\x89\\xbc\\x1e\\xfe\\xed\\xbbG`\\xf3\\xbc\\xf9E\\xf4\\xbc\\x8d\\x87\\x80<\\x9e\\x83\\xc6\\xbb\\x99$~\\xb9tL\\xbb;O\\xf9\\xeb\\xbcw\\xae\\xb4<\\x88P\\x01\\xbdO\\xbc\\x8a\\xbc\\xc2\\xf6\\xde\\xbcI\\xa5T\\xbc\\x81dE;\\x83\\x9eu<?\\xd2+\\xbd\\x1d)h<&2<;\\x1a\\xd2\\x9f<\\xf2\\xd4D\\xbb<\\xe0\\x8d\\xbc\\xd84\\xd5\\xbb*i;:\\xe1\\x85\\xbb\\xba\\xeb\\x10R<Y\\x1f\\xd8\\xbc\\xd9\\x14\\x0c\\xbd\\xcaG\\xc5\\xbc\\xfb\\x95\\x86\\xbc\\x0fG\\x89\\xba\\xc3f:<\\xb7\\xbe\\x0b\\xbcM\\x07\\xce<\\x04L\\x17<(/\\x0b\\xbdzX\\xc0\\xba\\x7f\\x8f\\xbf\\xbc\\xe9\\x83\\xde<.\\xcb4\\xbc\\xa2U\\x1b\\xbc]\\xe6\\xfb<d\\xaan<\\x96\\x85\\xa3\\xbc2\\x02\\xb4\\xbc!C\\xcf<ui\\xd3\\xbbU\\x10\\xa2\\xbc?\\x8a\\x99<\\x1d\\xe1\\xd5\\xbc~*\\x95;\\x19b\\xc4\\xbc\\xf9\\x08\\x13\\xbc0\\xc8\\x03=\\xb7C\\x7f\\xb9i\\x99\\xdb<\\x129\\xa7\\xbcu\\xbc\\x96\\xbc\\xf9E\\xf4\\xbcT\\xe8\\xd8;\\xa89W;\\xd1SJ=\\xf0\\x8f\\xe3\\xbb\\x1e\\xfem\\xbc\\xee\\xc5\\x8e\\xbc\\x9aL\\xc7;\\r\\xf7\\xf6\\xbb\\xe6i\\xf7;~*\\x15=\\x96z\\xf2<\\xe6!\\xe5\\xbb-f\\n\\xbc\\\\\\x81\\xd1;`S&<P!\\xb5\\xbbc\\xfd1\\xbb\\xc78\\x0f=\"#\\x06\\xbd\\x0egR\\xbc\\xd6\\xb2\\x92\\xbd\\x10\\x1c\\x0f=1\\xda\\xea\\xbbE\\xde0:\\rr\\x03\\xbbR\\xa3w\\xbb\\x06>5<LZ\\x11\\xbc\\x02w\\x91<3\\xafp<\\xd5\\x8a\\xc97\\x15H];\\xc8\\x02d\\xbbv\\x86\\xeb<\\xf2D\\xa0\\xbc\\x08\\x83\\x16<\\xc8\\r\\x15=\\xdc\\x06\\xaa\\xbc\\xc4\\x8e\\x03<l\\xb3\\xc2\\xbc\\xd9\\xa40\\xbaq\\xeaA\\xbc\\xb5\\xe9\\x85<b(,\\xbal\\xb3\\xc2;e\\x8a\\xa5\\xbbQ\\x91\\x10;\\x19\\x1a\\xb2<\\xacpV\\xbcy\\x83:\\xbc\\xb7\\xbe\\x0b=\\xc9r\\xbf\\xbc\\xba]f<\\x8f\\xc1\\xb0<,\\xae\\x1c<l\\xfbT\\xbc\\xdf\\xb05\\xb9\\x98/\\xaf<_+\\xdd\\xbb\\xf2\\x8c\\xb2:\\xe7>};\\xb34I\\xbcVu\\xcc;\\xa3\\r\\x89<5\\xf4Q;\\x85\\x9bD;\\xeb\\x1b\\x03;v\\xd9\\xae<WU\\x83<\\xb4\\x14\\x80< \\xd3\\xf3:\\xaa+\\xf5<\\xed\\xe5\\xd7\\xbc(l\\xec\\xbb\\xf1\\xac\\xfb\\xbb\\xb1_C\\xbc\\x0c\\x92L<Z\\x8f\\xb3<eB\\x93;2\\x92X\\xbbr\\x12\\x0b=\\xde\\xdb/;\\xc5\\xab\\x9b<.;\\x10;\\x84\\xc6><\\xd4%\\x9f<WJR\\xbcX\\x02\\xc0<#\\xf8\\x8b<D\\xb6\\xe7\\xbb\\xdc\\xfb\\xf8\\xbc\\xe3\\xbfk<=E8<\\xd9\\\\\\x9e<2\\x92\\xd8\\xbb\\xff\\\\*\\xbc\\xc3\\x1e\\xa8<\\xb51\\x18\\xbc\\x19\\x1a\\xb2\\xbc\\xfb\\xfa\\xb0;\\x08\\x83\\x16=\\n\\x10\\x8a\\xbc\\xd6\\xa7\\xe1\\xbc\\x8f\\xb6\\xff:Z\\xff\\x0e=\\xf9\\xfda\\xbc\\xbd\\x12#\\xbc\\xd1\\xb8t:\\xb7\\xb3\\xda\\xbb`\\x9b8<\\xf1\\'\\x88\\xbcf\\xefO\\xbb\\xfd\\xcf\\xb6<ut\\x04;\\x80\\xb7\\x88;C\\xa4\\x00:\\xba]f\\xba_~ ;\\r\\xafd;\\xfa\\xdd\\x98<\\xb5\\xc1<<3\\x1f\\xcc\\xbb.\\x83\\xa2\\xbc;\\xb8D\\xbcy\\x83:\\xbc1\\x9d\\t<A\\x17\\x8d\\xbc\\xaa+\\xf5\\xbc\\x11\\x81\\xb9;\\x85\\xee\\x87\\xbc\\x15\\x9b <\\xf0R\\x02=\\xa89W\\xbcU\\xc8\\x8f<\\x91\\x06\\x92:\\xa0\\xa0^<<p\\xb2\\xbce\\x8a\\xa5\\xbc\\x80\\xf4\\xe9\\xbbo\\xb0\\x11=\\x7fG-\\xbbN\\xdc\\xd3;H\\x88<\\xbb\\xc3\\x1e\\xa8\\xbb\\x0c\\xda^\\xba_6\\x8e\\xbc\\xd3\\x08\\x87<j1\\x00\\xbd\\xbd\\xca\\x90;\\x17(\\x94;\\xaa6\\xa6\\xbb1\\x9d\\x89\\xbc\\xe4\\x94\\xf1\\xbb\\x0f<\\xd8\\xbc(w\\x9d\\xbbuiS<\\x90&\\xdb\\xbcP!\\xb5<<p2\\xbb\\xd3P\\x99=\\xdb\\x96\\xce<\\xb3\\xec6\\xbc\\xd4\\xb5C<\\xf6\\x9bh\\xbc,\\xf6\\xae;\\xa3\\xba\\xc5;{\\x10.;,\\xeb\\xfd\\xbc\\xb2\\xc4\\xed\\xbcB\\xc4I<\\x0f\\xcc|\\xbc\\x98\\xca\\x84;\\xc7\\xe5K\\xbd\\xcdD\\x94\\xbc\\x129\\'\\xbc\\xaf\\xd2\\xcf\\xbb\\x8b\\xef\\xdb<\\xbf\\x9f\\x96\\xbc\\x81\\xc9o\\xbc\\xf8P\\xa5<\\x08\\x13\\xbb\\xbb$]6<+\\x16\\xf8<db\\xdc\\xbc\\x83\\x19\\x02;\\xb4\\x99s\\xba\\xe1\\xad\\x84\\xbb\\x97\\xa2\\xbb\\xbb\\xa3\\x02X\\xbd\\x15\\x90\\xef\\xbb\\xd9Qm:.\\xcb\\xb4\\xbcYgj\\xbc\\xf9\\xc0\\x80\\xbc1\\x9d\\t;\\x99\\x94Y<w\\xf6\\xc6\\xbb}U\\x0f=\\x11\\x81\\xb9\\xbc\\x86\\x0b\\xa0\\xbc\\xd9\\\\\\x9e<V-:\\xbc\\x80\\xacW\\xbc\\xb2\\x171<\\xaa\\xee\\x93\\xbc\\x9c\\x01\\x84\\xbbK\\xea5\\xbc\\xe8f\\xc6\\xbc'\n",
      "Results: Result{2 total, docs: [Document {'id': 'focusedlabsdoc:12b850c6-7990-4ba0-add3-21bcb1ec2c03_Chicago_IRL_Agenda_2023_.pdf-!0', 'payload': None, 'vector_score': '0.123921394348', 'filename': '12b850c6-7990-4ba0-add3-21bcb1ec2c03_Chicago_IRL_Agenda_2023_.pdf', 'text_chunk': 'Filename is: 12b850c6-7990-4ba0-add3-21bcb1ec2c03_Chicago_IRL_Agenda_2023_.pdf; Chicago IRL Agenda 2023     Wednesday, August 9, 2023  Arrive to Chicago mid/late afternoon. TBD on agenda for the evening..     Thursday, August 10, 2023    Time    Activity    8:00 - 8:45am    Breakfast    Details    12:00 -    Lunch    Friday, August 11, 2023    Time    8:00    Activity    Breakfast    Details    Chicago IRL Agenda 20231🗓  \\x0cTime    Activity    Details    10:30 - 11am    Closing Ceremony    11:00 - 12:00pm    12:00pm    Lunch    Finish!    Chicago IRL Agenda 20232\\x0c'}, Document {'id': 'focusedlabsdoc:bec4fe49-b23a-4eec-b46d-88cb4e1d60e0_2023_Chicago_IRL_.pdf-!1', 'payload': None, 'vector_score': '0.126851916313', 'filename': 'bec4fe49-b23a-4eec-b46d-88cb4e1d60e0_2023_Chicago_IRL_.pdf', 'text_chunk': '    ✈ Travel & Logistics    🗓 Chicago IRL Agenda 2023     2023 Chicago IRL2⚠  \\x0c'}]}\n",
      "**************************\n",
      "result_df:    id  \\\n",
      "0  0    \n",
      "1  1    \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     result  \\\n",
      "0  Filename is: 12b850c6-7990-4ba0-add3-21bcb1ec2c03_Chicago_IRL_Agenda_2023_.pdf; Chicago IRL Agenda 2023     Wednesday, August 9, 2023  Arrive to Chicago mid/late afternoon. TBD on agenda for the evening..     Thursday, August 10, 2023    Time    Activity    8:00 - 8:45am    Breakfast    Details    12:00 -    Lunch    Friday, August 11, 2023    Time    8:00    Activity    Breakfast    Details    Chicago IRL Agenda 20231🗓  \fTime    Activity    Details    10:30 - 11am    Closing Ceremony    11:00 - 12:00pm    12:00pm    Lunch    Finish!    Chicago IRL Agenda 20232\f   \n",
      "1      ✈ Travel & Logistics    🗓 Chicago IRL Agenda 2023     2023 Chicago IRL2⚠  \f                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "        certainty  \n",
      "0  0.123921394348  \n",
      "1  0.126851916313  \n",
      "- 2023 Chicago IRL is scheduled for August 9-11, 2023\n",
      "- Wednesday August 9: Arrive in Chicago in the afternoon, TBD on evening agenda\n",
      "- Thursday August 10: 8:00am-8:45am breakfast, 12:00pm- lunch\n",
      "- Friday August 11: 8:00am breakfast, 10:30am-11am closing ceremony, 12:00pm lunch\n",
      "CPU times: user 17.1 ms, sys: 9.71 ms, total: 26.8 ms\n",
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fl_query= 'when is the 2023 Chicago IRL scheduled for?'\n",
    "\n",
    "result_df = get_redis_results(redis_client, fl_query, index_name=INDEX_NAME)\n",
    "print(f\"result_df: {result_df}\")\n",
    "result_df.head(2)\n",
    "\n",
    "# Build a prompt to provide the original query, the result and ask to summarise for the user\n",
    "summary_prompt = '''Summarise this result in a bulleted list to answer the search query a customer has sent.\n",
    "Search query: SEARCH_QUERY_HERE\n",
    "Search result: SEARCH_RESULT_HERE\n",
    "Summary:\n",
    "'''\n",
    "summary_prepped = summary_prompt.replace('SEARCH_QUERY_HERE', fl_query).replace('SEARCH_RESULT_HERE', result_df['result'][0])\n",
    "summary = openai.Completion.create(engine=COMPLETIONS_MODEL,prompt=summary_prepped,max_tokens=500)\n",
    "# Response provided by GPT-3\n",
    "print(summary['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d008ff23",
   "metadata": {},
   "source": [
    "### Search\n",
    "\n",
    "Now that we've got our knowledge embedded and stored in Redis, we can now create an internal search application. Its not sophisticated but it'll get the job done for us.\n",
    "\n",
    "In the directory containing this app, execute ```streamlit run search.py```. This will open up a Streamlit app in your browser where you can ask questions of your embedded data.\n",
    "\n",
    "__Example Questions__:\n",
    "- what is the cost cap for a power unit in 2023\n",
    "- what should competitors include on their application form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12b31e",
   "metadata": {},
   "source": [
    "## Build your moat\n",
    "\n",
    "The Q&A was useful, but fairly limited in the complexity of interaction we can have - if the user asks a sub-optimal question, there is no assistance from the system to prompt them for more info or conversation to lead them down the right path.\n",
    "\n",
    "For the next step we'll make a Chatbot using the Chat Completions endpoint, which will:\n",
    "- Be given instructions on how it should act and what the goals of its users are\n",
    "- Be supplied some required information that it needs to collect\n",
    "- Go back and forth with the customer until it has populated that information\n",
    "- Say a trigger word that will kick off semantic search and summarisation of the response\n",
    "\n",
    "For more details on our Chat Completions endpoint and how to interact with it, please check out the docs [here](https://platform.openai.com/docs/guides/chat)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34135886",
   "metadata": {},
   "source": [
    "### Framework\n",
    "\n",
    "This section outlines a basic framework for working with the API and storing context of previous conversation \"turns\". Once this is established, we'll extend it to use our retrieval endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45c0acc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:40.704718Z",
     "start_time": "2023-05-31T23:35:38.999244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: As an AI language model, I am programmed to assist you with any queries or tasks you may have. Please let me know what you need help with, and I will do my best to assist you in any way possible.\n"
     ]
    }
   ],
   "source": [
    "# A basic example of how to interact with our ChatCompletion endpoint\n",
    "# It requires a list of \"messages\", consisting of a \"role\" (one of system, user or assistant) and \"content\"\n",
    "question = 'How can you help me'\n",
    "\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "  ]\n",
    ")\n",
    "print(f\"{completion['choices'][0]['message']['role']}: {completion['choices'][0]['message']['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23e4fc55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:40.752921Z",
     "start_time": "2023-05-31T23:35:40.703304Z"
    }
   },
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "# A basic class to create a message as a dict for chat\n",
    "class Message:\n",
    "    \n",
    "    \n",
    "    def __init__(self,role,content):\n",
    "        \n",
    "        self.role = role\n",
    "        self.content = content\n",
    "        \n",
    "    def message(self):\n",
    "        \n",
    "        return {\"role\": self.role,\"content\": self.content}\n",
    "        \n",
    "# Our assistant class we'll use to converse with the bot\n",
    "class Assistant:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def _get_assistant_response(self, prompt):\n",
    "        \n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "              model=\"gpt-3.5-turbo\",\n",
    "              messages=prompt\n",
    "            )\n",
    "            \n",
    "            response_message = Message(completion['choices'][0]['message']['role'],completion['choices'][0]['message']['content'])\n",
    "            return response_message.message()\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            return f'Request failed with exception {e}'\n",
    "\n",
    "    def ask_assistant(self, next_user_prompt, colorize_assistant_replies=True):\n",
    "        [self.conversation_history.append(x) for x in next_user_prompt]\n",
    "        assistant_response = self._get_assistant_response(self.conversation_history)\n",
    "        self.conversation_history.append(assistant_response)\n",
    "        return assistant_response\n",
    "            \n",
    "        \n",
    "    def pretty_print_conversation_history(self, colorize_assistant_replies=True):\n",
    "        for entry in self.conversation_history:\n",
    "            if entry['role'] == 'system':\n",
    "                pass\n",
    "            else:\n",
    "                prefix = entry['role']\n",
    "                content = entry['content']\n",
    "                output = colored(prefix +':\\n' + content, 'green') if colorize_assistant_replies and entry['role'] == 'assistant' else prefix +':\\n' + content\n",
    "                print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e18c88b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:40.761020Z",
     "start_time": "2023-05-31T23:35:40.730497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'role': 'system',\n  'content': 'You are a helpful business assistant who has innovative ideas'},\n {'role': 'user', 'content': 'What can you do to help me'}]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate our Assistant class\n",
    "conversation = Assistant()\n",
    "\n",
    "# Create a list to hold our messages and insert both a system message to guide behaviour and our first user question\n",
    "messages = []\n",
    "system_message = Message('system','You are a helpful business assistant who has innovative ideas')\n",
    "user_message = Message('user','What can you do to help me')\n",
    "messages.append(system_message.message())\n",
    "messages.append(user_message.message())\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "377243c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:42.293225Z",
     "start_time": "2023-05-31T23:35:40.753084Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[71], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Get back a response from the Chatbot to our question\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m response_message \u001B[38;5;241m=\u001B[39m \u001B[43mconversation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mask_assistant\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(response_message[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "Cell \u001B[0;32mIn[69], line 39\u001B[0m, in \u001B[0;36mAssistant.ask_assistant\u001B[0;34m(self, next_user_prompt, colorize_assistant_replies)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mask_assistant\u001B[39m(\u001B[38;5;28mself\u001B[39m, next_user_prompt, colorize_assistant_replies\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m     38\u001B[0m     [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconversation_history\u001B[38;5;241m.\u001B[39mappend(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m next_user_prompt]\n\u001B[0;32m---> 39\u001B[0m     assistant_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_assistant_response\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconversation_history\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconversation_history\u001B[38;5;241m.\u001B[39mappend(assistant_response)\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m assistant_response\n",
      "Cell \u001B[0;32mIn[69], line 25\u001B[0m, in \u001B[0;36mAssistant._get_assistant_response\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_assistant_response\u001B[39m(\u001B[38;5;28mself\u001B[39m, prompt):\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 25\u001B[0m         completion \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m          \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-3.5-turbo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m          \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m         response_message \u001B[38;5;241m=\u001B[39m Message(completion[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m'\u001B[39m],completion[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response_message\u001B[38;5;241m.\u001B[39mmessage()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001B[0m, in \u001B[0;36mChatCompletion.create\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 25\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TryAgain \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m start \u001B[38;5;241m+\u001B[39m timeout:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    137\u001B[0m ):\n\u001B[1;32m    138\u001B[0m     (\n\u001B[1;32m    139\u001B[0m         deployment_id,\n\u001B[1;32m    140\u001B[0m         engine,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    150\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[1;32m    151\u001B[0m     )\n\u001B[0;32m--> 153\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[1;32m    165\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_requestor.py:216\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    207\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    215\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m--> 216\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_raw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[43m        \u001B[49m\u001B[43msupplied_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response(result, stream)\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_requestor.py:516\u001B[0m, in \u001B[0;36mAPIRequestor.request_raw\u001B[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    514\u001B[0m     _thread_context\u001B[38;5;241m.\u001B[39msession \u001B[38;5;241m=\u001B[39m _make_session()\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 516\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_thread_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mabs_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mTIMEOUT_SECS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    526\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mTimeout(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequest timed out: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    585\u001B[0m }\n\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[0;32m--> 489\u001B[0m         resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m            \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m            \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m            \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m            \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m            \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    502\u001B[0m     \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[1;32m    503\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(conn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproxy_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_proxy(conn)\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n\u001B[1;32m    717\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    444\u001B[0m             httplib_response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m    445\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m--> 449\u001B[0m             \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;66;03m# Python 3\u001B[39;00m\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m         httplib_response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m         \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m         \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[1;32m    449\u001B[0m         six\u001B[38;5;241m.\u001B[39mraise_from(e, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:1374\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1372\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1373\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1374\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1375\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1376\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:279\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 279\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/ssl.py:1274\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1271\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1272\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1273\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1274\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/ssl.py:1130\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1129\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1130\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Get back a response from the Chatbot to our question\n",
    "response_message = conversation.ask_assistant(messages)\n",
    "print(response_message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364c3b5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-31T23:35:42.292614Z"
    }
   },
   "outputs": [],
   "source": [
    "next_question = 'Tell me more about option 2'\n",
    "\n",
    "# Initiate a fresh messages list and insert our next question\n",
    "messages = []\n",
    "user_message = Message('user',next_question)\n",
    "messages.append(user_message.message())\n",
    "response_message = conversation.ask_assistant(messages)\n",
    "print(response_message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62842a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a log of our conversation so far\n",
    "\n",
    "conversation.pretty_print_conversation_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d5b54",
   "metadata": {},
   "source": [
    "### Knowledge retrieval\n",
    "\n",
    "Now we'll extend the class to call a downstream service when a stop sequence is spoken by the Chatbot.\n",
    "\n",
    "The main changes are:\n",
    "- The system message is more comprehensive, giving criteria for the Chatbot to advance the conversation\n",
    "- Adding an explicit stop sequence for it to use when it has the info it needs\n",
    "- Extending the class with a function ```_get_search_results``` which sources Redis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import OPENAI_API_KEY\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Updated system prompt requiring Question and Year to be extracted from the user\n",
    "system_prompt = '''\n",
    "You are a helpful virtual assistant for the employees of Focused Labs. Focused Labs is a boutique Software Consulting firm that specializes in enterprise application development and digital transformation. Employees will ask you questions about the inner workings of the company. Questions could range in areas such as process, procedure, policy, and culture. Employees have different roles. The roles are either Developer, Designer, or Product Manager. The question is about how the company of Focused Labs operates. For each question, you need to capture their role.\n",
    "If they haven't provided their role, ask them for it.\n",
    "Once you have their role, say \"let me check on that for you...\".\n",
    "\n",
    "Example 1:\n",
    "\n",
    "User: I'd like to know how many IRLs Focused Labs has hosted\n",
    "\n",
    "Assistant: Certainly, what is your role at the Company?\n",
    "\n",
    "User: I am a designer.\n",
    "\n",
    "Assistant: let me check on that for you...\n",
    "'''\n",
    "\n",
    "# New Assistant class to add a vector database call to its responses\n",
    "class RetrievalAssistant:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conversation_history = []  \n",
    "\n",
    "    def _get_assistant_response(self, prompt):\n",
    "        \n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "              model=CHAT_MODEL,\n",
    "              messages=prompt,\n",
    "              temperature=0.1\n",
    "            )\n",
    "            \n",
    "            response_message = Message(completion['choices'][0]['message']['role'],completion['choices'][0]['message']['content'])\n",
    "            return response_message.message()\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            return f'Request failed with exception {e}'\n",
    "    \n",
    "    # The function to retrieve Redis search results\n",
    "    def _get_search_results(self,prompt):\n",
    "        latest_question = prompt\n",
    "        search_content = get_redis_results(redis_client,latest_question,INDEX_NAME)['result'][0]\n",
    "        return search_content\n",
    "        \n",
    "\n",
    "    def ask_assistant(self, next_user_prompt):\n",
    "        [self.conversation_history.append(x) for x in next_user_prompt]\n",
    "        assistant_response = self._get_assistant_response(self.conversation_history)\n",
    "        \n",
    "        # Answer normally unless the trigger sequence is used \"searching_for_answers\"\n",
    "        if 'let me check on that for you...' in assistant_response['content'].lower():\n",
    "            question_extract = openai.Completion.create(model=COMPLETIONS_MODEL,prompt=f\"Extract the employees' latest question and their role from this conversation: {self.conversation_history}. Extract it as a sentence stating their question question and their role\")\n",
    "            search_result = self._get_search_results(question_extract['choices'][0]['text'])\n",
    "            \n",
    "            # We insert an extra system prompt here to give fresh context to the Chatbot on how to use the Redis results\n",
    "            # In this instance we add it to the conversation history, but in production it may be better to hide\n",
    "            self.conversation_history.insert(-1,{\"role\": 'system',\"content\": f\"Answer the user's question using this content: {search_result}. If you cannot answer the question, say 'Sorry, I don't know the answer to this one. You should call Austin Vance at (970) 306-8100' and he will be happy to provide an answer. He is easiest to reach between the hours of 2am and 4am MDT\"})\n",
    "            #[self.conversation_history.append(x) for x in next_user_prompt]\n",
    "            \n",
    "            assistant_response = self._get_assistant_response(self.conversation_history)\n",
    "            print(next_user_prompt)\n",
    "            print(assistant_response)\n",
    "            self.conversation_history.append(assistant_response)\n",
    "            return assistant_response\n",
    "        else:\n",
    "            self.conversation_history.append(assistant_response)\n",
    "            return assistant_response\n",
    "            \n",
    "        \n",
    "    def pretty_print_conversation_history(self, colorize_assistant_replies=True):\n",
    "        for entry in self.conversation_history:\n",
    "            if entry['role'] == 'system':\n",
    "                pass\n",
    "            else:\n",
    "                prefix = entry['role']\n",
    "                content = entry['content']\n",
    "                output = colored(prefix +':\\n' + content, 'green') if colorize_assistant_replies and entry['role'] == 'assistant' else prefix +':\\n' + content\n",
    "                #prefix = entry['role']\n",
    "                print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = RetrievalAssistant()\n",
    "messages = []\n",
    "system_message = Message('system',system_prompt)\n",
    "user_message = Message('user','What is a Focused Labs IRL?')\n",
    "messages.append(system_message.message())\n",
    "messages.append(user_message.message())\n",
    "response_message = conversation.ask_assistant(messages)\n",
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702eb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "user_message = Message('user','I am a designer!')\n",
    "messages.append(user_message.message())\n",
    "response_message = conversation.ask_assistant(messages)\n",
    "#response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.pretty_print_conversation_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9ef37",
   "metadata": {},
   "source": [
    "### Chatbot\n",
    "\n",
    "Now we'll put all this into action with a real (basic) Chatbot.\n",
    "\n",
    "In the directory containing this app, execute ```streamlit run chat.py```. This will open up a Streamlit app in your browser where you can ask questions of your embedded data. \n",
    "\n",
    "__Example Questions__:\n",
    "- what is the cost cap for a power unit in 2023\n",
    "- what should competitors include on their application form\n",
    "- how can a competitor be disqualified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6c4ca",
   "metadata": {},
   "source": [
    "### Consolidation\n",
    "\n",
    "Over the course of this notebook you have:\n",
    "- Laid the foundations of your product by embedding our knowledge base\n",
    "- Created a Q&A application to serve basic use cases\n",
    "- Extended this to be an interactive Chatbot\n",
    "\n",
    "These are the foundational building blocks of any Q&A or Chat application using our APIs - these are your starting point, and we look forward to seeing what you build with them!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
