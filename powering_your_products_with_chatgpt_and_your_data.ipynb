{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63785634",
   "metadata": {},
   "source": [
    "# Power your products with ChatGPT and your own data\n",
    "\n",
    "This is a walkthrough taking readers through how to build starter Q&A and Chatbot applications using the ChatGPT API and their own data. \n",
    "\n",
    "It is laid out in these sections:\n",
    "- **Setup:** \n",
    "    - Initiate variables and source the data\n",
    "- **Lay the foundations:**\n",
    "    - Set up the vector database to accept vectors and data\n",
    "    - Load the dataset, chunk the data up for embedding and store in the vector database\n",
    "- **Make it a product:**\n",
    "    - Add a retrieval step where users provide queries and we return the most relevant entries\n",
    "    - Summarise search results with GPT-3\n",
    "    - Test out this basic Q&A app in Streamlit\n",
    "- **Build your moat:**\n",
    "    - Create an Assistant class to manage context and interact with our bot\n",
    "    - Use the Chatbot to answer questions using semantic search context\n",
    "    - Test out this basic Chatbot app in Streamlit\n",
    "    \n",
    "Upon completion, you have the building blocks to create your own production chatbot or Q&A application using OpenAI APIs and a vector database.\n",
    "\n",
    "This notebook was originally presented with [these slides](https://drive.google.com/file/d/1dB-RQhZC_Q1iAsHkNNdkqtxxXqYODFYy/view?usp=share_link), which provide visual context for this journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59f08ea7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:25.778700Z",
     "start_time": "2023-05-31T23:28:25.573880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbb963fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.540326Z",
     "start_time": "2023-05-31T23:28:25.631824Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.24.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.24.2)\r\n",
      "Requirement already satisfied: openai==0.27.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (0.27.1)\r\n",
      "Requirement already satisfied: pandas==1.5.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (1.5.3)\r\n",
      "Requirement already satisfied: redis==4.5.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.5.1)\r\n",
      "Requirement already satisfied: requests==2.28.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (2.28.2)\r\n",
      "Requirement already satisfied: streamlit==1.20.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.20.0)\r\n",
      "Requirement already satisfied: streamlit_chat==0.0.2.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.0.2.2)\r\n",
      "Requirement already satisfied: termcolor==2.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (2.2.0)\r\n",
      "Requirement already satisfied: jupyter in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (1.0.0)\r\n",
      "Requirement already satisfied: ipykernel in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (6.22.0)\r\n",
      "Requirement already satisfied: textract in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (1.6.5)\r\n",
      "Requirement already satisfied: tiktoken in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (0.3.3)\r\n",
      "Requirement already satisfied: pdfminer in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (20191125)\r\n",
      "Requirement already satisfied: tqdm in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from openai==0.27.1->-r requirements.txt (line 2)) (4.65.0)\r\n",
      "Requirement already satisfied: aiohttp in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from openai==0.27.1->-r requirements.txt (line 2)) (3.8.4)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 3)) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 3)) (2023.3)\r\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from redis==4.5.1->-r requirements.txt (line 4)) (4.0.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from requests==2.28.2->-r requirements.txt (line 5)) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from requests==2.28.2->-r requirements.txt (line 5)) (3.4)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from requests==2.28.2->-r requirements.txt (line 5)) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from requests==2.28.2->-r requirements.txt (line 5)) (2022.12.7)\r\n",
      "Requirement already satisfied: altair<5,>=3.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (4.2.2)\r\n",
      "Requirement already satisfied: blinker>=1.0.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (1.6.2)\r\n",
      "Requirement already satisfied: cachetools>=4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (5.3.0)\r\n",
      "Requirement already satisfied: click>=7.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (8.1.3)\r\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (6.6.0)\r\n",
      "Requirement already satisfied: packaging>=14.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (23.1)\r\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (9.5.0)\r\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (3.20.3)\r\n",
      "Requirement already satisfied: pyarrow>=4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (11.0.0)\r\n",
      "Requirement already satisfied: pympler>=0.9 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (1.0.1)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (13.3.5)\r\n",
      "Requirement already satisfied: semver in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (3.0.0)\r\n",
      "Requirement already satisfied: toml in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (0.10.2)\r\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (4.5.0)\r\n",
      "Requirement already satisfied: tzlocal>=1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (4.3)\r\n",
      "Requirement already satisfied: validators>=0.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (0.20.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (3.1.31)\r\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (0.8.1b0)\r\n",
      "Requirement already satisfied: tornado>=6.0.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from streamlit==1.20.0->-r requirements.txt (line 6)) (6.3.1)\r\n",
      "Requirement already satisfied: notebook in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (6.5.4)\r\n",
      "Requirement already satisfied: qtconsole in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (5.4.2)\r\n",
      "Requirement already satisfied: jupyter-console in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (6.6.3)\r\n",
      "Requirement already satisfied: nbconvert in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (7.3.1)\r\n",
      "Requirement already satisfied: ipywidgets in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter->-r requirements.txt (line 9)) (8.0.6)\r\n",
      "Requirement already satisfied: appnope in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (0.1.3)\r\n",
      "Requirement already satisfied: comm>=0.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (0.1.3)\r\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (1.6.7)\r\n",
      "Requirement already satisfied: ipython>=7.23.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (8.12.0)\r\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (8.2.0)\r\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (5.3.0)\r\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (0.1.6)\r\n",
      "Requirement already satisfied: nest-asyncio in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (1.5.6)\r\n",
      "Requirement already satisfied: psutil in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (5.9.5)\r\n",
      "Requirement already satisfied: pyzmq>=20 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (25.0.2)\r\n",
      "Requirement already satisfied: traitlets>=5.4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipykernel->-r requirements.txt (line 10)) (5.9.0)\r\n",
      "Requirement already satisfied: argcomplete~=1.10.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (1.10.3)\r\n",
      "Requirement already satisfied: beautifulsoup4~=4.8.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (4.8.2)\r\n",
      "Requirement already satisfied: chardet==3.* in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (3.0.4)\r\n",
      "Requirement already satisfied: docx2txt~=0.8 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (0.8)\r\n",
      "Requirement already satisfied: extract-msg<=0.29.* in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (0.28.7)\r\n",
      "Requirement already satisfied: pdfminer.six==20191110 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (20191110)\r\n",
      "Requirement already satisfied: python-pptx~=0.6.18 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (0.6.21)\r\n",
      "Requirement already satisfied: six~=1.12.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (1.12.0)\r\n",
      "Requirement already satisfied: SpeechRecognition~=3.8.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (3.8.1)\r\n",
      "Requirement already satisfied: xlrd~=1.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract->-r requirements.txt (line 11)) (1.2.0)\r\n",
      "Requirement already satisfied: pycryptodome in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pdfminer.six==20191110->textract->-r requirements.txt (line 11)) (3.17)\r\n",
      "Requirement already satisfied: sortedcontainers in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pdfminer.six==20191110->textract->-r requirements.txt (line 11)) (2.4.0)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from tiktoken->-r requirements.txt (line 12)) (2023.3.23)\r\n",
      "Requirement already satisfied: entrypoints in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (0.4)\r\n",
      "Requirement already satisfied: jinja2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (3.1.2)\r\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (4.17.3)\r\n",
      "Requirement already satisfied: toolz in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (0.12.0)\r\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from beautifulsoup4~=4.8.0->textract->-r requirements.txt (line 11)) (2.4.1)\r\n",
      "Requirement already satisfied: imapclient==2.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract->-r requirements.txt (line 11)) (2.1.0)\r\n",
      "Requirement already satisfied: olefile>=0.46 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract->-r requirements.txt (line 11)) (0.46)\r\n",
      "Requirement already satisfied: compressed-rtf>=1.0.6 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract->-r requirements.txt (line 11)) (1.0.6)\r\n",
      "Requirement already satisfied: ebcdic>=1.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract->-r requirements.txt (line 11)) (1.1.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from gitpython!=3.1.19->streamlit==1.20.0->-r requirements.txt (line 6)) (4.0.10)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from importlib-metadata>=1.4->streamlit==1.20.0->-r requirements.txt (line 6)) (3.15.0)\r\n",
      "Requirement already satisfied: backcall in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.2.0)\r\n",
      "Requirement already satisfied: decorator in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (5.1.1)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.18.2)\r\n",
      "Requirement already satisfied: pickleshare in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.7.5)\r\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (3.0.38)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (2.15.1)\r\n",
      "Requirement already satisfied: stack-data in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.6.2)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (4.8.0)\r\n",
      "Requirement already satisfied: platformdirs>=2.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 10)) (3.5.0)\r\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract->-r requirements.txt (line 11)) (4.9.2)\r\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract->-r requirements.txt (line 11)) (3.1.0)\r\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from rich>=10.11.0->streamlit==1.20.0->-r requirements.txt (line 6)) (2.2.0)\r\n",
      "Requirement already satisfied: pytz-deprecation-shim in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from tzlocal>=1.1->streamlit==1.20.0->-r requirements.txt (line 6)) (0.1.0.post0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (23.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (1.9.2)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (1.3.3)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from aiohttp->openai==0.27.1->-r requirements.txt (line 2)) (1.3.1)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 9)) (4.0.7)\r\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 9)) (3.0.7)\r\n",
      "Requirement already satisfied: bleach in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (6.0.0)\r\n",
      "Requirement already satisfied: defusedxml in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (0.7.1)\r\n",
      "Requirement already satisfied: jupyterlab-pygments in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (0.2.2)\r\n",
      "Requirement already satisfied: markupsafe>=2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (2.1.2)\r\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (2.0.5)\r\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (0.7.4)\r\n",
      "Requirement already satisfied: nbformat>=5.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (5.8.0)\r\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (1.5.0)\r\n",
      "Requirement already satisfied: tinycss2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbconvert->jupyter->-r requirements.txt (line 9)) (1.2.1)\r\n",
      "Requirement already satisfied: argon2-cffi in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (21.3.0)\r\n",
      "Requirement already satisfied: ipython-genutils in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (0.2.0)\r\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (1.8.2)\r\n",
      "Requirement already satisfied: terminado>=0.8.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (0.17.1)\r\n",
      "Requirement already satisfied: prometheus-client in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (0.16.0)\r\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from notebook->jupyter->-r requirements.txt (line 9)) (0.5.6)\r\n",
      "Requirement already satisfied: qtpy>=2.0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from qtconsole->jupyter->-r requirements.txt (line 9)) (2.3.1)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit==1.20.0->-r requirements.txt (line 6)) (5.0.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.8.3)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (0.19.3)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit==1.20.0->-r requirements.txt (line 6)) (0.1.2)\r\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (2.5.0)\r\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.2.3)\r\n",
      "Requirement already satisfied: fastjsonschema in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 9)) (2.16.3)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.2.6)\r\n",
      "Requirement already satisfied: argon2-cffi-bindings in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 9)) (21.2.0)\r\n",
      "Requirement already satisfied: webencodings in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 9)) (0.5.1)\r\n",
      "Requirement already satisfied: tzdata in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit==1.20.0->-r requirements.txt (line 6)) (2023.3)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (1.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (2.2.1)\r\n",
      "Requirement already satisfied: pure-eval in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from stack-data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 10)) (0.2.2)\r\n",
      "Requirement already satisfied: anyio>=3.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (3.6.2)\r\n",
      "Requirement already satisfied: jupyter-events>=0.4.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.6.3)\r\n",
      "Requirement already satisfied: jupyter-server-terminals in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.4.4)\r\n",
      "Requirement already satisfied: websocket-client in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (1.5.1)\r\n",
      "Requirement already satisfied: cffi>=1.0.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 9)) (1.15.1)\r\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from anyio>=3.1.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (1.3.0)\r\n",
      "Requirement already satisfied: pycparser in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->-r requirements.txt (line 9)) (2.21)\r\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (2.0.7)\r\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (6.0)\r\n",
      "Requirement already satisfied: rfc3339-validator in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.1.4)\r\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jupyter-events>=0.4.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->jupyter->-r requirements.txt (line 9)) (0.1.1)\r\n",
      "Requirement already satisfied: fqdn in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (1.5.1)\r\n",
      "Requirement already satisfied: isoduration in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (20.11.0)\r\n",
      "Requirement already satisfied: jsonpointer>1.13 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (2.3)\r\n",
      "Requirement already satisfied: uri-template in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (1.2.0)\r\n",
      "Requirement already satisfied: webcolors>=1.11 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (1.13)\r\n",
      "Requirement already satisfied: arrow>=0.15.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from isoduration->jsonschema>=3.0->altair<5,>=3.2.0->streamlit==1.20.0->-r requirements.txt (line 6)) (1.2.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13649895",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First we'll setup our libraries and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7590fbfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.568790Z",
     "start_time": "2023-05-31T23:28:27.541752Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Iterator\n",
    "import tiktoken\n",
    "import textract\n",
    "from numpy import array, average\n",
    "\n",
    "from database import get_redis_connection\n",
    "\n",
    "# Set our default models and chunking size\n",
    "from config import COMPLETIONS_MODEL, EMBEDDINGS_MODEL, CHAT_MODEL, TEXT_EMBEDDING_CHUNK_SIZE, VECTOR_FIELD_NAME\n",
    "\n",
    "# Ignore unclosed SSL socket warnings - optional in case you get these errors\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"unclosed\", category=ImportWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "760efc1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.583132Z",
     "start_time": "2023-05-31T23:28:27.568960Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f90817d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.602117Z",
     "start_time": "2023-05-31T23:28:27.585045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['12b850c6-7990-4ba0-add3-21bcb1ec2c03_Chicago_IRL_Agenda_2023_.pdf',\n '2fae12d2-0deb-4ab2-aa2f-04d9d2f6dd65_Lightning_Talks.pdf',\n '4aff6d37-802a-4579-ae4a-c314432d5c35_Denver_IRL_Agenda_2023.pdf',\n '51b50db6-e1ed-41cb-8b4e-db8ee8dc3373_FamilyFriend_Day_Friday_-_Invite_Info.pdf',\n '6df71481-fe62-4b59-9a65-ed7487dd5dd3_Activities_and_Meals.pdf',\n '927af3b9-ae55-46ce-bd38-72f733b62aee_2023_Denver_IRL.pdf',\n '9b909996-d5b7-4674-bb38-e10535348f00_Travel__Logistics.pdf',\n '9d39fbe7-bce2-4f34-b836-4786bbc2316a_Travel__Logistics.pdf',\n 'bec4fe49-b23a-4eec-b46d-88cb4e1d60e0_2023_Chicago_IRL_.pdf',\n 'd72d8c47-d368-48b5-833e-2ed59df54cd9_Ski_Weekend.pdf']"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(os.curdir,'data')\n",
    "pdf_files = sorted([x for x in os.listdir(data_dir) if 'DS_Store' not in x])\n",
    "pdf_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4018c",
   "metadata": {},
   "source": [
    "## Laying the foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632b82ed",
   "metadata": {},
   "source": [
    "### Storage\n",
    "\n",
    "We're going to use Redis as our database for both document contents and the vector embeddings. You will need the full Redis Stack to enable use of Redisearch, which is the module that allows semantic search - more detail is in the [docs for Redis Stack](https://redis.io/docs/stack/get-started/install/docker/).\n",
    "\n",
    "To set this up locally, you will need to install Docker and then run the following command: ```docker run -d --name redis-stack -p 6379:6379 -p 8001:8001 redis/redis-stack:latest```.\n",
    "\n",
    "The code used here draws heavily on [this repo](https://github.com/RedisAI/vecsim-demo).\n",
    "\n",
    "After setting up the Docker instance of Redis Stack, you can follow the below instructions to initiate a Redis connection and create a Hierarchical Navigable Small World (HNSW) index for semantic search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17d6b886",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.613994Z",
     "start_time": "2023-05-31T23:28:27.599567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup Redis\n",
    "from redis import Redis\n",
    "from redis.commands.search.query import Query\n",
    "from redis.commands.search.field import (\n",
    "    TextField,\n",
    "    VectorField,\n",
    "    NumericField\n",
    ")\n",
    "from redis.commands.search.indexDefinition import (\n",
    "    IndexDefinition,\n",
    "    IndexType\n",
    ")\n",
    "\n",
    "redis_client = get_redis_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4f3d3e6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.646719Z",
     "start_time": "2023-05-31T23:28:27.613448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "VECTOR_DIM = 1536 #len(data['title_vector'][0]) # length of the vectors\n",
    "#VECTOR_NUMBER = len(data)                 # initial number of vectors\n",
    "PREFIX = \"focusedlabsdoc\"                            # prefix for the document keys\n",
    "DISTANCE_METRIC = \"COSINE\"                # distance metric for the vectors (ex. COSINE, IP, L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d3c352ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.653969Z",
     "start_time": "2023-05-31T23:28:27.626150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create search index\n",
    "\n",
    "# Index\n",
    "INDEX_NAME = \"fl-index\"           # name of the search index\n",
    "VECTOR_FIELD_NAME = 'content_vector'\n",
    "\n",
    "# Define RediSearch fields for each of the columns in the dataset\n",
    "# This is where you should add any additional metadata you want to capture\n",
    "filename = TextField(\"filename\")\n",
    "text_chunk = TextField(\"text_chunk\")\n",
    "file_chunk_index = NumericField(\"file_chunk_index\")\n",
    "\n",
    "# define RediSearch vector fields to use HNSW index\n",
    "\n",
    "text_embedding = VectorField(VECTOR_FIELD_NAME,\n",
    "    \"HNSW\", {\n",
    "        \"TYPE\": \"FLOAT32\",\n",
    "        \"DIM\": VECTOR_DIM,\n",
    "        \"DISTANCE_METRIC\": DISTANCE_METRIC\n",
    "    }\n",
    ")\n",
    "# Add all our field objects to a list to be created as an index\n",
    "fields = [filename,text_chunk,file_chunk_index,text_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a6c78b7e",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.661947Z",
     "start_time": "2023-05-31T23:28:27.646887Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redis_client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cf3ad41f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.694023Z",
     "start_time": "2023-05-31T23:28:27.660651Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown Index name\n",
      "Not there yet. Creating\n"
     ]
    }
   ],
   "source": [
    "# Optional step to drop the index if it already exists\n",
    "#redis_client.ft(INDEX_NAME).dropindex()\n",
    "\n",
    "# Check if index exists\n",
    "try:\n",
    "    redis_client.ft(INDEX_NAME).info()\n",
    "    print(\"Index already exists\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    # Create RediSearch Index\n",
    "    print('Not there yet. Creating')\n",
    "    redis_client.ft(INDEX_NAME).create_index(\n",
    "        fields = fields,\n",
    "        definition = IndexDefinition(prefix=[PREFIX], index_type=IndexType.HASH)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74ebeb5",
   "metadata": {},
   "source": [
    "### Ingestion\n",
    "\n",
    "We'll load up our PDFs and do the following\n",
    "- Initiate our tokenizer\n",
    "- Run a processing pipeline to:\n",
    "    - Mine the text from each PDF\n",
    "    - Split them into chunks and embed them\n",
    "    - Store them in Redis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ed23bf9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:27.706610Z",
     "start_time": "2023-05-31T23:28:27.687632Z"
    }
   },
   "outputs": [],
   "source": [
    "# The transformers.py file contains all of the transforming functions, including ones to chunk, embed and load data\n",
    "# For more details the file and work through each function individually\n",
    "from transformers import handle_file_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3912ecdd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:28:28.626341Z",
     "start_time": "2023-05-31T23:28:27.705645Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textract in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (1.6.5)\r\n",
      "Requirement already satisfied: argcomplete~=1.10.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (1.10.3)\r\n",
      "Requirement already satisfied: beautifulsoup4~=4.8.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (4.8.2)\r\n",
      "Requirement already satisfied: chardet==3.* in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (3.0.4)\r\n",
      "Requirement already satisfied: docx2txt~=0.8 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (0.8)\r\n",
      "Requirement already satisfied: extract-msg<=0.29.* in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (0.28.7)\r\n",
      "Requirement already satisfied: pdfminer.six==20191110 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (20191110)\r\n",
      "Requirement already satisfied: python-pptx~=0.6.18 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (0.6.21)\r\n",
      "Requirement already satisfied: six~=1.12.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (1.12.0)\r\n",
      "Requirement already satisfied: SpeechRecognition~=3.8.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (3.8.1)\r\n",
      "Requirement already satisfied: xlrd~=1.2.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from textract) (1.2.0)\r\n",
      "Requirement already satisfied: pycryptodome in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (3.17)\r\n",
      "Requirement already satisfied: sortedcontainers in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pdfminer.six==20191110->textract) (2.4.0)\r\n",
      "Requirement already satisfied: soupsieve>=1.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from beautifulsoup4~=4.8.0->textract) (2.4.1)\r\n",
      "Requirement already satisfied: imapclient==2.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (2.1.0)\r\n",
      "Requirement already satisfied: olefile>=0.46 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (0.46)\r\n",
      "Requirement already satisfied: tzlocal>=2.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (4.3)\r\n",
      "Requirement already satisfied: compressed-rtf>=1.0.6 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (1.0.6)\r\n",
      "Requirement already satisfied: ebcdic>=1.1.1 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from extract-msg<=0.29.*->textract) (1.1.1)\r\n",
      "Requirement already satisfied: lxml>=3.1.0 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (4.9.2)\r\n",
      "Requirement already satisfied: Pillow>=3.3.2 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (9.5.0)\r\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from python-pptx~=0.6.18->textract) (3.1.0)\r\n",
      "Requirement already satisfied: pytz-deprecation-shim in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from tzlocal>=2.1->extract-msg<=0.29.*->textract) (0.1.0.post0)\r\n",
      "Requirement already satisfied: tzdata in /Users/luke/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal>=2.1->extract-msg<=0.29.*->textract) (2023.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install textract --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "31f299f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:36:19.426161Z",
     "start_time": "2023-05-31T23:35:47.936461Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/12b850c6-7990-4ba0-add3-21bcb1ec2c03_Chicago_IRL_Agenda_2023_.pdf\n",
      "./data/2fae12d2-0deb-4ab2-aa2f-04d9d2f6dd65_Lightning_Talks.pdf\n",
      "./data/4aff6d37-802a-4579-ae4a-c314432d5c35_Denver_IRL_Agenda_2023.pdf\n",
      "[handle_file_string] Error creating embedding: The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3f8b0a4afb61a74b2d758f99d66b51fa in your message.) {\n",
      "  \"error\": {\n",
      "    \"message\": \"The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3f8b0a4afb61a74b2d758f99d66b51fa in your message.)\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'The server had an error while processing your request. Sorry about that! You can retry your request, or contact us through our help center at help.openai.com if the error persists. (Please include the request ID 3f8b0a4afb61a74b2d758f99d66b51fa in your message.)', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Wed, 31 May 2023 23:36:19 GMT', 'Content-Type': 'application/json', 'Content-Length': '366', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-organization': 'user-ga0guzqsb2opdfa8waitcmyp', 'openai-processing-ms': '30025', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '60', 'x-ratelimit-remaining-requests': '58', 'x-ratelimit-reset-requests': '1.995s', 'x-request-id': '3f8b0a4afb61a74b2d758f99d66b51fa', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '7d0309142ab403c8-ORD', 'alt-svc': 'h3=\":443\"; ma=86400'}\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'text_embeddings' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:16\u001B[0m\n",
      "File \u001B[0;32m~/workspace/ai_develper_assistant/transformers.py:91\u001B[0m, in \u001B[0;36mhandle_file_string\u001B[0;34m(file, tokenizer, redis_conn, text_embedding_field, index_name)\u001B[0m\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m# Get the vectors array of triples: file_chunk_id, embedding, metadata for each embedding\u001B[39;00m\n\u001B[1;32m     89\u001B[0m \u001B[38;5;66;03m# Metadata is a dict with keys: filename, file_chunk_index\u001B[39;00m\n\u001B[1;32m     90\u001B[0m vectors \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 91\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, (text_chunk, embedding) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[43mtext_embeddings\u001B[49m):\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;28mid\u001B[39m \u001B[38;5;241m=\u001B[39m get_unique_id_for_file_chunk(filename, i)\n\u001B[1;32m     93\u001B[0m     vectors\u001B[38;5;241m.\u001B[39mappend(({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;28mid\u001B[39m\n\u001B[1;32m     94\u001B[0m         , \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvector\u001B[39m\u001B[38;5;124m\"\u001B[39m: embedding, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m'\u001B[39m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfilename\u001B[39m\u001B[38;5;124m\"\u001B[39m: filename\n\u001B[1;32m     95\u001B[0m             , \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext_chunk\u001B[39m\u001B[38;5;124m\"\u001B[39m: text_chunk\n\u001B[1;32m     96\u001B[0m             , \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile_chunk_index\u001B[39m\u001B[38;5;124m\"\u001B[39m: i}}))\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m: local variable 'text_embeddings' referenced before assignment"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This step takes about 5 minutes\n",
    "\n",
    "# Initialise tokenizer\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# Process each PDF file and prepare for embedding\n",
    "for pdf_file in pdf_files:\n",
    "    \n",
    "    pdf_path = os.path.join(data_dir,pdf_file)\n",
    "    print(pdf_path)\n",
    "    \n",
    "    # Extract the raw text from each PDF using textract\n",
    "    text = textract.process(pdf_path, method='pdfminer')\n",
    "    \n",
    "    # Chunk each document, embed the contents and load to Redis\n",
    "    handle_file_string((pdf_file,text.decode(\"utf-8\")),tokenizer,redis_client,VECTOR_FIELD_NAME,INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "22aff597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:38.495338Z",
     "start_time": "2023-05-31T23:35:38.436129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'10'"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that our docs have been inserted\n",
    "redis_client.ft(INDEX_NAME).info()['num_docs']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b12cb6e",
   "metadata": {},
   "source": [
    "## Make it a product\n",
    "\n",
    "Now we can test that our search works as intended by:\n",
    "- Querying our data in Redis using semantic search and verifying results\n",
    "- Adding a step to pass the results to GPT-3 for summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e921ac96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:38.495796Z",
     "start_time": "2023-05-31T23:35:38.476313Z"
    }
   },
   "outputs": [],
   "source": [
    "from database import get_redis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cb9dfacf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:38.999786Z",
     "start_time": "2023-05-31T23:35:38.496649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** Querying Redis *****\n",
      "Original Query: when is the 2023 Chicago IRL scheduled for?\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRemoteDisconnected\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    445\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m--> 449\u001B[0m             \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m     httplib_response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m     \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:1374\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1374\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1375\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:287\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m line:\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Presumably, the server closed the connection before\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# sending a valid response.\u001B[39;00m\n\u001B[0;32m--> 287\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RemoteDisconnected(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRemote end closed connection without\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    288\u001B[0m                              \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m response\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mRemoteDisconnected\u001B[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mProtocolError\u001B[0m                             Traceback (most recent call last)",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    488\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[0;32m--> 489\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[1;32m    503\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    785\u001B[0m     e \u001B[38;5;241m=\u001B[39m ProtocolError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConnection aborted.\u001B[39m\u001B[38;5;124m\"\u001B[39m, e)\n\u001B[0;32m--> 787\u001B[0m retries \u001B[38;5;241m=\u001B[39m \u001B[43mretries\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mincrement\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_pool\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexc_info\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    790\u001B[0m retries\u001B[38;5;241m.\u001B[39msleep()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/util/retry.py:550\u001B[0m, in \u001B[0;36mRetry.increment\u001B[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001B[0m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m read \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_method_retryable(method):\n\u001B[0;32m--> 550\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43merror\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_stacktrace\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    551\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m read \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/packages/six.py:769\u001B[0m, in \u001B[0;36mreraise\u001B[0;34m(tp, value, tb)\u001B[0m\n\u001B[1;32m    768\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m value\u001B[38;5;241m.\u001B[39m__traceback__ \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tb:\n\u001B[0;32m--> 769\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m value\u001B[38;5;241m.\u001B[39mwith_traceback(tb)\n\u001B[1;32m    770\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m value\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    445\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m--> 449\u001B[0m             \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m     httplib_response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m     \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m     \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m     \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:1374\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1374\u001B[0m     \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1375\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:287\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m line:\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Presumably, the server closed the connection before\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# sending a valid response.\u001B[39;00m\n\u001B[0;32m--> 287\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m RemoteDisconnected(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRemote end closed connection without\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    288\u001B[0m                              \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m response\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    289\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "\u001B[0;31mProtocolError\u001B[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mConnectionError\u001B[0m                           Traceback (most recent call last)",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_requestor.py:516\u001B[0m, in \u001B[0;36mAPIRequestor.request_raw\u001B[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 516\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_thread_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mabs_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mTIMEOUT_SECS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/adapters.py:547\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    546\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m--> 547\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m MaxRetryError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[0;31mConnectionError\u001B[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mAPIConnectionError\u001B[0m                        Traceback (most recent call last)",
      "File \u001B[0;32m<timed exec>:3\u001B[0m\n",
      "File \u001B[0;32m~/workspace/ai_develper_assistant/database.py:77\u001B[0m, in \u001B[0;36mget_redis_results\u001B[0;34m(redis_conn, query, index_name)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_redis_results\u001B[39m(redis_conn, query, index_name):\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;66;03m# Get most relevant documents from Redis\u001B[39;00m\n\u001B[0;32m---> 77\u001B[0m     query_result \u001B[38;5;241m=\u001B[39m \u001B[43mquery_redis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mredis_conn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m     \u001B[38;5;66;03m# Extract info into a list\u001B[39;00m\n\u001B[1;32m     80\u001B[0m     query_result_list \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[0;32m~/workspace/ai_develper_assistant/database.py:54\u001B[0m, in \u001B[0;36mquery_redis\u001B[0;34m(redis_conn, query, index_name, top_k)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOriginal Query: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mquery\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     53\u001B[0m \u001B[38;5;66;03m## Creates embedding vector from user query\u001B[39;00m\n\u001B[0;32m---> 54\u001B[0m embedded_query \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(\u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mEmbedding\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEMBEDDINGS_MODEL\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     57\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124membedding\u001B[39m\u001B[38;5;124m'\u001B[39m], dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mfloat32)\u001B[38;5;241m.\u001B[39mtobytes()\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEmbedded Query: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00membedded_query\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     60\u001B[0m \u001B[38;5;66;03m# prepare the query\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_resources/embedding.py:33\u001B[0m, in \u001B[0;36mEmbedding.create\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 33\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m         \u001B[38;5;66;03m# If a user specifies base64, we'll just return the encoded string.\u001B[39;00m\n\u001B[1;32m     36\u001B[0m         \u001B[38;5;66;03m# This is only for the default case.\u001B[39;00m\n\u001B[1;32m     37\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m user_provided_encoding_format:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    137\u001B[0m ):\n\u001B[1;32m    138\u001B[0m     (\n\u001B[1;32m    139\u001B[0m         deployment_id,\n\u001B[1;32m    140\u001B[0m         engine,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    150\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[1;32m    151\u001B[0m     )\n\u001B[0;32m--> 153\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[1;32m    165\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_requestor.py:216\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    207\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    215\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m--> 216\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_raw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[43m        \u001B[49m\u001B[43msupplied_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response(result, stream)\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_requestor.py:528\u001B[0m, in \u001B[0;36mAPIRequestor.request_raw\u001B[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    526\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mTimeout(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequest timed out: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    527\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mRequestException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m--> 528\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mAPIConnectionError(\n\u001B[1;32m    529\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError communicating with OpenAI: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(e)\n\u001B[1;32m    530\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n\u001B[1;32m    531\u001B[0m util\u001B[38;5;241m.\u001B[39mlog_debug(\n\u001B[1;32m    532\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOpenAI API response\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    533\u001B[0m     path\u001B[38;5;241m=\u001B[39mabs_url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    536\u001B[0m     request_id\u001B[38;5;241m=\u001B[39mresult\u001B[38;5;241m.\u001B[39mheaders\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX-Request-Id\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m    537\u001B[0m )\n\u001B[1;32m    538\u001B[0m \u001B[38;5;66;03m# Don't read the whole stream for debug logging unless necessary.\u001B[39;00m\n",
      "\u001B[0;31mAPIConnectionError\u001B[0m: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "fl_query= 'when is the 2023 Chicago IRL scheduled for?'\n",
    "\n",
    "result_df = get_redis_results(redis_client, fl_query, index_name=INDEX_NAME)\n",
    "print(f\"result_df: {result_df}\")\n",
    "result_df.head(2)\n",
    "\n",
    "# Build a prompt to provide the original query, the result and ask to summarise for the user\n",
    "summary_prompt = '''Summarise this result in a bulleted list to answer the search query a customer has sent.\n",
    "Search query: SEARCH_QUERY_HERE\n",
    "Search result: SEARCH_RESULT_HERE\n",
    "Summary:\n",
    "'''\n",
    "summary_prepped = summary_prompt.replace('SEARCH_QUERY_HERE', fl_query).replace('SEARCH_RESULT_HERE', result_df['result'][0])\n",
    "summary = openai.Completion.create(engine=COMPLETIONS_MODEL,prompt=summary_prepped,max_tokens=500)\n",
    "# Response provided by GPT-3\n",
    "print(summary['choices'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d008ff23",
   "metadata": {},
   "source": [
    "### Search\n",
    "\n",
    "Now that we've got our knowledge embedded and stored in Redis, we can now create an internal search application. Its not sophisticated but it'll get the job done for us.\n",
    "\n",
    "In the directory containing this app, execute ```streamlit run search.py```. This will open up a Streamlit app in your browser where you can ask questions of your embedded data.\n",
    "\n",
    "__Example Questions__:\n",
    "- what is the cost cap for a power unit in 2023\n",
    "- what should competitors include on their application form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12b31e",
   "metadata": {},
   "source": [
    "## Build your moat\n",
    "\n",
    "The Q&A was useful, but fairly limited in the complexity of interaction we can have - if the user asks a sub-optimal question, there is no assistance from the system to prompt them for more info or conversation to lead them down the right path.\n",
    "\n",
    "For the next step we'll make a Chatbot using the Chat Completions endpoint, which will:\n",
    "- Be given instructions on how it should act and what the goals of its users are\n",
    "- Be supplied some required information that it needs to collect\n",
    "- Go back and forth with the customer until it has populated that information\n",
    "- Say a trigger word that will kick off semantic search and summarisation of the response\n",
    "\n",
    "For more details on our Chat Completions endpoint and how to interact with it, please check out the docs [here](https://platform.openai.com/docs/guides/chat)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34135886",
   "metadata": {},
   "source": [
    "### Framework\n",
    "\n",
    "This section outlines a basic framework for working with the API and storing context of previous conversation \"turns\". Once this is established, we'll extend it to use our retrieval endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45c0acc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:40.704718Z",
     "start_time": "2023-05-31T23:35:38.999244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant: As an AI language model, I am programmed to assist you with any queries or tasks you may have. Please let me know what you need help with, and I will do my best to assist you in any way possible.\n"
     ]
    }
   ],
   "source": [
    "# A basic example of how to interact with our ChatCompletion endpoint\n",
    "# It requires a list of \"messages\", consisting of a \"role\" (one of system, user or assistant) and \"content\"\n",
    "question = 'How can you help me'\n",
    "\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \"content\": question}\n",
    "  ]\n",
    ")\n",
    "print(f\"{completion['choices'][0]['message']['role']}: {completion['choices'][0]['message']['content']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23e4fc55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:40.752921Z",
     "start_time": "2023-05-31T23:35:40.703304Z"
    }
   },
   "outputs": [],
   "source": [
    "from termcolor import colored\n",
    "\n",
    "# A basic class to create a message as a dict for chat\n",
    "class Message:\n",
    "    \n",
    "    \n",
    "    def __init__(self,role,content):\n",
    "        \n",
    "        self.role = role\n",
    "        self.content = content\n",
    "        \n",
    "    def message(self):\n",
    "        \n",
    "        return {\"role\": self.role,\"content\": self.content}\n",
    "        \n",
    "# Our assistant class we'll use to converse with the bot\n",
    "class Assistant:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conversation_history = []\n",
    "\n",
    "    def _get_assistant_response(self, prompt):\n",
    "        \n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "              model=\"gpt-3.5-turbo\",\n",
    "              messages=prompt\n",
    "            )\n",
    "            \n",
    "            response_message = Message(completion['choices'][0]['message']['role'],completion['choices'][0]['message']['content'])\n",
    "            return response_message.message()\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            return f'Request failed with exception {e}'\n",
    "\n",
    "    def ask_assistant(self, next_user_prompt, colorize_assistant_replies=True):\n",
    "        [self.conversation_history.append(x) for x in next_user_prompt]\n",
    "        assistant_response = self._get_assistant_response(self.conversation_history)\n",
    "        self.conversation_history.append(assistant_response)\n",
    "        return assistant_response\n",
    "            \n",
    "        \n",
    "    def pretty_print_conversation_history(self, colorize_assistant_replies=True):\n",
    "        for entry in self.conversation_history:\n",
    "            if entry['role'] == 'system':\n",
    "                pass\n",
    "            else:\n",
    "                prefix = entry['role']\n",
    "                content = entry['content']\n",
    "                output = colored(prefix +':\\n' + content, 'green') if colorize_assistant_replies and entry['role'] == 'assistant' else prefix +':\\n' + content\n",
    "                print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e18c88b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:40.761020Z",
     "start_time": "2023-05-31T23:35:40.730497Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'role': 'system',\n  'content': 'You are a helpful business assistant who has innovative ideas'},\n {'role': 'user', 'content': 'What can you do to help me'}]"
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate our Assistant class\n",
    "conversation = Assistant()\n",
    "\n",
    "# Create a list to hold our messages and insert both a system message to guide behaviour and our first user question\n",
    "messages = []\n",
    "system_message = Message('system','You are a helpful business assistant who has innovative ideas')\n",
    "user_message = Message('user','What can you do to help me')\n",
    "messages.append(system_message.message())\n",
    "messages.append(user_message.message())\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "377243c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-31T23:35:42.293225Z",
     "start_time": "2023-05-31T23:35:40.753084Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[71], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Get back a response from the Chatbot to our question\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m response_message \u001B[38;5;241m=\u001B[39m \u001B[43mconversation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mask_assistant\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmessages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(response_message[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "Cell \u001B[0;32mIn[69], line 39\u001B[0m, in \u001B[0;36mAssistant.ask_assistant\u001B[0;34m(self, next_user_prompt, colorize_assistant_replies)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mask_assistant\u001B[39m(\u001B[38;5;28mself\u001B[39m, next_user_prompt, colorize_assistant_replies\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m     38\u001B[0m     [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconversation_history\u001B[38;5;241m.\u001B[39mappend(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m next_user_prompt]\n\u001B[0;32m---> 39\u001B[0m     assistant_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_assistant_response\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconversation_history\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconversation_history\u001B[38;5;241m.\u001B[39mappend(assistant_response)\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m assistant_response\n",
      "Cell \u001B[0;32mIn[69], line 25\u001B[0m, in \u001B[0;36mAssistant._get_assistant_response\u001B[0;34m(self, prompt)\u001B[0m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_assistant_response\u001B[39m(\u001B[38;5;28mself\u001B[39m, prompt):\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 25\u001B[0m         completion \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m          \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgpt-3.5-turbo\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m          \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprompt\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     30\u001B[0m         response_message \u001B[38;5;241m=\u001B[39m Message(completion[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrole\u001B[39m\u001B[38;5;124m'\u001B[39m],completion[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mchoices\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     31\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response_message\u001B[38;5;241m.\u001B[39mmessage()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001B[0m, in \u001B[0;36mChatCompletion.create\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 25\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TryAgain \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m start \u001B[38;5;241m+\u001B[39m timeout:\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    137\u001B[0m ):\n\u001B[1;32m    138\u001B[0m     (\n\u001B[1;32m    139\u001B[0m         deployment_id,\n\u001B[1;32m    140\u001B[0m         engine,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    150\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[1;32m    151\u001B[0m     )\n\u001B[0;32m--> 153\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[1;32m    165\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_requestor.py:216\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    207\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    215\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[0;32m--> 216\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest_raw\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlower\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    218\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    220\u001B[0m \u001B[43m        \u001B[49m\u001B[43msupplied_headers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    225\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response(result, stream)\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/openai/api_requestor.py:516\u001B[0m, in \u001B[0;36mAPIRequestor.request_raw\u001B[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    514\u001B[0m     _thread_context\u001B[38;5;241m.\u001B[39msession \u001B[38;5;241m=\u001B[39m _make_session()\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 516\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_thread_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mabs_url\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfiles\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfiles\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    523\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mTIMEOUT_SECS\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    524\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    525\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m requests\u001B[38;5;241m.\u001B[39mexceptions\u001B[38;5;241m.\u001B[39mTimeout \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    526\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m error\u001B[38;5;241m.\u001B[39mTimeout(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRequest timed out: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/sessions.py:587\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    582\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    583\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    584\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    585\u001B[0m }\n\u001B[1;32m    586\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 587\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    589\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/sessions.py:701\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    698\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    700\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    704\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/requests/adapters.py:489\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    487\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    488\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m chunked:\n\u001B[0;32m--> 489\u001B[0m         resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    490\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    491\u001B[0m \u001B[43m            \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    492\u001B[0m \u001B[43m            \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    493\u001B[0m \u001B[43m            \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[43m            \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    495\u001B[0m \u001B[43m            \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    496\u001B[0m \u001B[43m            \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    497\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m            \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    502\u001B[0m     \u001B[38;5;66;03m# Send the request.\u001B[39;00m\n\u001B[1;32m    503\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(conn, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mproxy_pool\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:703\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001B[0m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_prepare_proxy(conn)\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Make the request on the httplib connection object.\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    704\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    706\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    707\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    708\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    709\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    710\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    711\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    713\u001B[0m \u001B[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001B[39;00m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001B[39;00m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;66;03m# it will also try to release it and we'll have a double-release\u001B[39;00m\n\u001B[1;32m    716\u001B[0m \u001B[38;5;66;03m# mess.\u001B[39;00m\n\u001B[1;32m    717\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:449\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    444\u001B[0m             httplib_response \u001B[38;5;241m=\u001B[39m conn\u001B[38;5;241m.\u001B[39mgetresponse()\n\u001B[1;32m    445\u001B[0m         \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m             \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m             \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m             \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[0;32m--> 449\u001B[0m             \u001B[43msix\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraise_from\u001B[49m\u001B[43m(\u001B[49m\u001B[43me\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m<string>:3\u001B[0m, in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/envs/openai/lib/python3.10/site-packages/urllib3/connectionpool.py:444\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    442\u001B[0m     \u001B[38;5;66;03m# Python 3\u001B[39;00m\n\u001B[1;32m    443\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 444\u001B[0m         httplib_response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    445\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mBaseException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    446\u001B[0m         \u001B[38;5;66;03m# Remove the TypeError from the exception chain in\u001B[39;00m\n\u001B[1;32m    447\u001B[0m         \u001B[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001B[39;00m\n\u001B[1;32m    448\u001B[0m         \u001B[38;5;66;03m# Otherwise it looks like a bug in the code.\u001B[39;00m\n\u001B[1;32m    449\u001B[0m         six\u001B[38;5;241m.\u001B[39mraise_from(e, \u001B[38;5;28;01mNone\u001B[39;00m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:1374\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1372\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1373\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1374\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1375\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1376\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/http/client.py:279\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 279\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/socket.py:705\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 705\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    707\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/ssl.py:1274\u001B[0m, in \u001B[0;36mSSLSocket.recv_into\u001B[0;34m(self, buffer, nbytes, flags)\u001B[0m\n\u001B[1;32m   1270\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m flags \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1271\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1272\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[1;32m   1273\u001B[0m           \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m)\n\u001B[0;32m-> 1274\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnbytes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1275\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1276\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001B[0;32m~/.pyenv/versions/3.10.7/lib/python3.10/ssl.py:1130\u001B[0m, in \u001B[0;36mSSLSocket.read\u001B[0;34m(self, len, buffer)\u001B[0m\n\u001B[1;32m   1128\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1129\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m buffer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1130\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sslobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbuffer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1131\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1132\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sslobj\u001B[38;5;241m.\u001B[39mread(\u001B[38;5;28mlen\u001B[39m)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# Get back a response from the Chatbot to our question\n",
    "response_message = conversation.ask_assistant(messages)\n",
    "print(response_message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f364c3b5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-31T23:35:42.292614Z"
    }
   },
   "outputs": [],
   "source": [
    "next_question = 'Tell me more about option 2'\n",
    "\n",
    "# Initiate a fresh messages list and insert our next question\n",
    "messages = []\n",
    "user_message = Message('user',next_question)\n",
    "messages.append(user_message.message())\n",
    "response_message = conversation.ask_assistant(messages)\n",
    "print(response_message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62842a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out a log of our conversation so far\n",
    "\n",
    "conversation.pretty_print_conversation_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18d5b54",
   "metadata": {},
   "source": [
    "### Knowledge retrieval\n",
    "\n",
    "Now we'll extend the class to call a downstream service when a stop sequence is spoken by the Chatbot.\n",
    "\n",
    "The main changes are:\n",
    "- The system message is more comprehensive, giving criteria for the Chatbot to advance the conversation\n",
    "- Adding an explicit stop sequence for it to use when it has the info it needs\n",
    "- Extending the class with a function ```_get_search_results``` which sources Redis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import OPENAI_API_KEY\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "# Updated system prompt requiring Question and Year to be extracted from the user\n",
    "system_prompt = '''\n",
    "You are a helpful virtual assistant for the employees of Focused Labs. Focused Labs is a boutique Software Consulting firm that specializes in enterprise application development and digital transformation. Employees will ask you questions about the inner workings of the company. Questions could range in areas such as process, procedure, policy, and culture. Employees have different roles. The roles are either Developer, Designer, or Product Manager. The question is about how the company of Focused Labs operates. For each question, you need to capture their role.\n",
    "If they haven't provided their role, ask them for it.\n",
    "Once you have their role, say \"let me check on that for you...\".\n",
    "\n",
    "Example 1:\n",
    "\n",
    "User: I'd like to know how many IRLs Focused Labs has hosted\n",
    "\n",
    "Assistant: Certainly, what is your role at the Company?\n",
    "\n",
    "User: I am a designer.\n",
    "\n",
    "Assistant: let me check on that for you...\n",
    "'''\n",
    "\n",
    "# New Assistant class to add a vector database call to its responses\n",
    "class RetrievalAssistant:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.conversation_history = []  \n",
    "\n",
    "    def _get_assistant_response(self, prompt):\n",
    "        \n",
    "        try:\n",
    "            completion = openai.ChatCompletion.create(\n",
    "              model=CHAT_MODEL,\n",
    "              messages=prompt,\n",
    "              temperature=0.1\n",
    "            )\n",
    "            \n",
    "            response_message = Message(completion['choices'][0]['message']['role'],completion['choices'][0]['message']['content'])\n",
    "            return response_message.message()\n",
    "            \n",
    "        except Exception as e:\n",
    "            \n",
    "            return f'Request failed with exception {e}'\n",
    "    \n",
    "    # The function to retrieve Redis search results\n",
    "    def _get_search_results(self,prompt):\n",
    "        latest_question = prompt\n",
    "        search_content = get_redis_results(redis_client,latest_question,INDEX_NAME)['result'][0]\n",
    "        return search_content\n",
    "        \n",
    "\n",
    "    def ask_assistant(self, next_user_prompt):\n",
    "        [self.conversation_history.append(x) for x in next_user_prompt]\n",
    "        assistant_response = self._get_assistant_response(self.conversation_history)\n",
    "        \n",
    "        # Answer normally unless the trigger sequence is used \"searching_for_answers\"\n",
    "        if 'let me check on that for you...' in assistant_response['content'].lower():\n",
    "            question_extract = openai.Completion.create(model=COMPLETIONS_MODEL,prompt=f\"Extract the employees' latest question and their role from this conversation: {self.conversation_history}. Extract it as a sentence stating their question question and their role\")\n",
    "            search_result = self._get_search_results(question_extract['choices'][0]['text'])\n",
    "            \n",
    "            # We insert an extra system prompt here to give fresh context to the Chatbot on how to use the Redis results\n",
    "            # In this instance we add it to the conversation history, but in production it may be better to hide\n",
    "            self.conversation_history.insert(-1,{\"role\": 'system',\"content\": f\"Answer the user's question using this content: {search_result}. If you cannot answer the question, say 'Sorry, I don't know the answer to this one. You should call Austin Vance at (970) 306-8100' and he will be happy to provide an answer. He is easiest to reach between the hours of 2am and 4am MDT\"})\n",
    "            #[self.conversation_history.append(x) for x in next_user_prompt]\n",
    "            \n",
    "            assistant_response = self._get_assistant_response(self.conversation_history)\n",
    "            print(next_user_prompt)\n",
    "            print(assistant_response)\n",
    "            self.conversation_history.append(assistant_response)\n",
    "            return assistant_response\n",
    "        else:\n",
    "            self.conversation_history.append(assistant_response)\n",
    "            return assistant_response\n",
    "            \n",
    "        \n",
    "    def pretty_print_conversation_history(self, colorize_assistant_replies=True):\n",
    "        for entry in self.conversation_history:\n",
    "            if entry['role'] == 'system':\n",
    "                pass\n",
    "            else:\n",
    "                prefix = entry['role']\n",
    "                content = entry['content']\n",
    "                output = colored(prefix +':\\n' + content, 'green') if colorize_assistant_replies and entry['role'] == 'assistant' else prefix +':\\n' + content\n",
    "                #prefix = entry['role']\n",
    "                print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101d502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = RetrievalAssistant()\n",
    "messages = []\n",
    "system_message = Message('system',system_prompt)\n",
    "user_message = Message('user','What is a Focused Labs IRL?')\n",
    "messages.append(system_message.message())\n",
    "messages.append(user_message.message())\n",
    "response_message = conversation.ask_assistant(messages)\n",
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702eb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = []\n",
    "user_message = Message('user','I am a designer!')\n",
    "messages.append(user_message.message())\n",
    "response_message = conversation.ask_assistant(messages)\n",
    "#response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2c812",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.pretty_print_conversation_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9ef37",
   "metadata": {},
   "source": [
    "### Chatbot\n",
    "\n",
    "Now we'll put all this into action with a real (basic) Chatbot.\n",
    "\n",
    "In the directory containing this app, execute ```streamlit run chat.py```. This will open up a Streamlit app in your browser where you can ask questions of your embedded data. \n",
    "\n",
    "__Example Questions__:\n",
    "- what is the cost cap for a power unit in 2023\n",
    "- what should competitors include on their application form\n",
    "- how can a competitor be disqualified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e6c4ca",
   "metadata": {},
   "source": [
    "### Consolidation\n",
    "\n",
    "Over the course of this notebook you have:\n",
    "- Laid the foundations of your product by embedding our knowledge base\n",
    "- Created a Q&A application to serve basic use cases\n",
    "- Extended this to be an interactive Chatbot\n",
    "\n",
    "These are the foundational building blocks of any Q&A or Chat application using our APIs - these are your starting point, and we look forward to seeing what you build with them!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
